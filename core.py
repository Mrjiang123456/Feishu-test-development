import os
import json
import glob
import aiohttp
import asyncio
import argparse
import traceback
import uuid  # æ·»åŠ uuidæ¨¡å—å¯¼å…¥
from config import (
    FORMATTED_AI_CASES_FILE,
    FORMATTED_GOLDEN_CASES_FILE,
    get_report_file_paths,
    API_URL,
    MODEL_NAME,
    AIOHTTP_TIMEOUT,
    AIOHTTP_CONNECTOR_LIMIT,
    AIOHTTP_CONNECTOR_TTL,
    MAX_CONCURRENT_REQUESTS
)
from logger import log, log_error, start_logging, end_logging
from formatter import format_test_cases
from evaluator import evaluate_test_cases, generate_markdown_report, evaluate_and_generate_report
from llm_api import clear_cache  # å¯¼å…¥æ¸…é™¤ç¼“å­˜å‡½æ•°


# --- ä¸»ç¨‹åº ---
async def async_main(ai_cases_data=None, golden_cases_data=None, is_iteration=False, prev_iteration_data=None):
    """
    ä¸»ç¨‹åºçš„å¼‚æ­¥ç‰ˆæœ¬

    :param ai_cases_data: AIç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹æ•°æ®ï¼ˆå¯é€‰ï¼‰ï¼ŒJSONå­—ç¬¦ä¸²
    :param golden_cases_data: é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹æ•°æ®ï¼ˆå¯é€‰ï¼‰ï¼ŒJSONå­—ç¬¦ä¸²
    :param is_iteration: æ˜¯å¦å¯ç”¨è¿­ä»£å‰åå¯¹æ¯”åŠŸèƒ½
    :param prev_iteration_data: ä¸Šä¸€æ¬¡è¿­ä»£çš„æµ‹è¯•ç”¨ä¾‹æ•°æ®ï¼ˆå¯é€‰ï¼‰ï¼ŒJSONå­—ç¬¦ä¸²
    """
    # æ¸…é™¤ä¹‹å‰çš„LLM APIè°ƒç”¨ç¼“å­˜ï¼Œç¡®ä¿æ¯æ¬¡è¯„æµ‹éƒ½æ˜¯å…¨æ–°çš„
    clear_cache()

    # ç”Ÿæˆä¼šè¯å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œé¿å…æ–‡ä»¶ç¼“å­˜é—®é¢˜
    session_id = str(uuid.uuid4())
    formatted_ai_cases_file = FORMATTED_AI_CASES_FILE.replace('.json', f'_{session_id}.json')
    formatted_golden_cases_file = FORMATTED_GOLDEN_CASES_FILE.replace('.json', f'_{session_id}.json')
    
    # å¦‚æœå¯ç”¨è¿­ä»£å¯¹æ¯”ï¼Œåˆ›å»ºä¸Šä¸€æ¬¡è¿­ä»£çš„æ ¼å¼åŒ–æ–‡ä»¶è·¯å¾„
    if is_iteration and prev_iteration_data:
        formatted_prev_iteration_file = FORMATTED_AI_CASES_FILE.replace('.json', f'_prev_{session_id}.json')
    else:
        formatted_prev_iteration_file = None

    start_logging()
    log("å¯åŠ¨æµ‹è¯•ç”¨ä¾‹è¯„æµ‹æµç¨‹", important=True)
    if is_iteration:
        log("å·²å¯ç”¨è¿­ä»£å‰åå¯¹æ¯”åŠŸèƒ½", important=True)

    # æ·»åŠ å°å»¶è¿Ÿï¼Œç¡®ä¿æ—¥å¿—é¡ºåº
    await asyncio.sleep(0.05)

    # è·å–å¸¦æœ‰å½“å‰æ—¶é—´æˆ³çš„æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
    report_file, report_json_file = get_report_file_paths()
    log(f"æœ¬æ¬¡è¯„æµ‹æŠ¥å‘Šå°†ä¿å­˜ä¸º: {report_file}", important=True)
    log(f"æœ¬æ¬¡è¯„æµ‹JSONç»“æœå°†ä¿å­˜ä¸º: {report_json_file}", important=True)

    # è®°å½•ç³»ç»Ÿç¯å¢ƒä¿¡æ¯ï¼Œç”¨äºè¯Šæ–­
    try:
        import platform
        import sys
        env_info = {
            "platform": platform.platform(),
            "python_version": sys.version,
            "api_url": API_URL,
            "model": MODEL_NAME,
        }
        log(f"ç³»ç»Ÿç¯å¢ƒä¿¡æ¯: {json.dumps(env_info, ensure_ascii=False)}")
    except Exception as e:
        log_error("è·å–ç³»ç»Ÿç¯å¢ƒä¿¡æ¯å¤±è´¥", e)

    # 1. åŠ è½½ç”¨ä¾‹æ•°æ®
    try:
        # å¹¶è¡ŒåŠ è½½AIæµ‹è¯•ç”¨ä¾‹ã€é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹å’Œä¸Šä¸€æ¬¡è¿­ä»£æµ‹è¯•ç”¨ä¾‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        async def load_ai_cases():
            if ai_cases_data is None:
                log("ä»æ–‡ä»¶åŠ è½½AIæµ‹è¯•ç”¨ä¾‹", important=True)
                try:
                    with open(FORMATTED_AI_CASES_FILE, 'r', encoding='utf-8') as f:
                        ai_text = f.read()
                        log(f"AIæµ‹è¯•ç”¨ä¾‹æ–‡ä»¶å¤§å°: {len(ai_text)} å­—èŠ‚")
                        return ai_text
                except FileNotFoundError:
                    error_info = {
                        "file_path": os.path.abspath(FORMATTED_AI_CASES_FILE),
                        "current_dir": os.getcwd(),
                        "available_files": os.listdir(os.path.dirname(FORMATTED_AI_CASES_FILE)) if os.path.exists(
                            os.path.dirname(FORMATTED_AI_CASES_FILE)) else "ç›®å½•ä¸å­˜åœ¨"
                    }
                    log_error(f"æ‰¾ä¸åˆ°AIæµ‹è¯•ç”¨ä¾‹æ–‡ä»¶ {FORMATTED_AI_CASES_FILE}", error_info)
                    return None
                except Exception as e:
                    log_error(f"è¯»å–AIæµ‹è¯•ç”¨ä¾‹æ–‡ä»¶ {FORMATTED_AI_CASES_FILE} å¤±è´¥", e)
                    return None
            else:
                log("ä½¿ç”¨ä¼ å…¥çš„AIæµ‹è¯•ç”¨ä¾‹æ•°æ®", important=True)
                return ai_cases_data

        async def load_golden_cases():
            if golden_cases_data is None:
                log("ä»æ–‡ä»¶åŠ è½½é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹", important=True)
                # æŸ¥æ‰¾goldensetæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰golden_cases*.jsonæ–‡ä»¶
                golden_files = glob.glob("goldenset/golden_cases*.json")

                if not golden_files:
                    error_info = {
                        "search_pattern": "goldenset/golden_cases*.json",
                        "current_dir": os.getcwd(),
                        "goldenset_exists": os.path.exists("goldenset"),
                        "goldenset_files": os.listdir("goldenset") if os.path.exists("goldenset") else "ç›®å½•ä¸å­˜åœ¨"
                    }
                    log_error("åœ¨goldensetæ–‡ä»¶å¤¹ä¸­æ‰¾ä¸åˆ°é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶", error_info)
                    return None

                # é»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„æ–‡ä»¶
                golden_file = golden_files[0]
                log(f"ä½¿ç”¨é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶: {golden_file}", important=True)

                try:
                    with open(golden_file, 'r', encoding='utf-8') as f:
                        golden_text = f.read()
                        log(f"é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶å¤§å°: {len(golden_text)} å­—èŠ‚")
                        return golden_text
                except FileNotFoundError:
                    error_info = {
                        "file_path": os.path.abspath(golden_file),
                        "current_dir": os.getcwd()
                    }
                    log_error(f"æ‰¾ä¸åˆ°é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶ {golden_file}", error_info)
                    return None
                except Exception as e:
                    log_error(f"è¯»å–é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶ {golden_file} å¤±è´¥", e)
                    return None
            else:
                log("ä½¿ç”¨ä¼ å…¥çš„é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹æ•°æ®", important=True)
                return golden_cases_data
                
        async def load_prev_iteration():
            if prev_iteration_data is None:
                log("æ²¡æœ‰æä¾›ä¸Šä¸€æ¬¡è¿­ä»£çš„æµ‹è¯•ç”¨ä¾‹æ•°æ®", level="WARNING")
                return None
            else:
                log("ä½¿ç”¨ä¼ å…¥çš„ä¸Šä¸€æ¬¡è¿­ä»£æµ‹è¯•ç”¨ä¾‹æ•°æ®", important=True)
                return prev_iteration_data

        # åˆ›å»ºä»»åŠ¡åˆ—è¡¨
        tasks = [
            asyncio.create_task(load_ai_cases()),
            asyncio.create_task(load_golden_cases())
        ]
        
        # å¦‚æœå¯ç”¨è¿­ä»£å¯¹æ¯”ï¼Œæ·»åŠ åŠ è½½ä¸Šä¸€æ¬¡è¿­ä»£æ•°æ®çš„ä»»åŠ¡
        if is_iteration:
            tasks.append(asyncio.create_task(load_prev_iteration()))

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = await asyncio.gather(*tasks)
        
        # è§£æç»“æœ
        if is_iteration:
            ai_cases_raw_text, golden_cases_raw_text, prev_iteration_raw_text = results
        else:
            ai_cases_raw_text, golden_cases_raw_text = results
            prev_iteration_raw_text = None

        if ai_cases_raw_text is None:
            end_logging()
            return {
                "success": False,
                "error": "åŠ è½½AIæµ‹è¯•ç”¨ä¾‹å¤±è´¥"
            }

        if golden_cases_raw_text is None:
            end_logging()
            return {
                "success": False,
                "error": "åŠ è½½é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹å¤±è´¥"
            }
            
        if is_iteration and prev_iteration_raw_text is None:
            log("è­¦å‘Šï¼šæ— æ³•åŠ è½½ä¸Šä¸€æ¬¡è¿­ä»£çš„æµ‹è¯•ç”¨ä¾‹æ•°æ®ï¼Œè¿­ä»£å¯¹æ¯”åŠŸèƒ½å°†è¢«ç¦ç”¨", level="WARNING")
            is_iteration = False

        # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†åŒé‡è½¬ä¹‰çš„JSONå­—ç¬¦ä¸²
        try:
            json.loads(ai_cases_raw_text)
        except json.JSONDecodeError:
            log("æ£€æµ‹åˆ°å¯èƒ½çš„åŒé‡è½¬ä¹‰JSONå­—ç¬¦ä¸²ï¼Œå°è¯•å¤„ç†", level="WARNING")
            try:
                # å°è¯•ä½¿ç”¨evalå¤„ç†
                parsed_data = eval(ai_cases_raw_text)
                if isinstance(parsed_data, dict):
                    ai_cases_raw_text = json.dumps(parsed_data)
                    log("æˆåŠŸå¤„ç†åŒé‡è½¬ä¹‰çš„JSONå­—ç¬¦ä¸²", important=True)
            except Exception as e:
                log_error(f"å¤„ç†åŒé‡è½¬ä¹‰JSONå¤±è´¥: {str(e)}")
                # ä¿æŒåŸæ ·
                
        # å¦‚æœå¯ç”¨è¿­ä»£å¯¹æ¯”ï¼ŒåŒæ ·æ£€æŸ¥ä¸Šä¸€æ¬¡è¿­ä»£æ•°æ®
        if is_iteration and prev_iteration_raw_text:
            try:
                json.loads(prev_iteration_raw_text)
            except json.JSONDecodeError:
                log("æ£€æµ‹åˆ°ä¸Šä¸€æ¬¡è¿­ä»£æ•°æ®å¯èƒ½æ˜¯åŒé‡è½¬ä¹‰JSONå­—ç¬¦ä¸²ï¼Œå°è¯•å¤„ç†", level="WARNING")
                try:
                    # å°è¯•ä½¿ç”¨evalå¤„ç†
                    parsed_data = eval(prev_iteration_raw_text)
                    if isinstance(parsed_data, dict):
                        prev_iteration_raw_text = json.dumps(parsed_data)
                        log("æˆåŠŸå¤„ç†ä¸Šä¸€æ¬¡è¿­ä»£æ•°æ®çš„åŒé‡è½¬ä¹‰JSONå­—ç¬¦ä¸²", important=True)
                except Exception as e:
                    log_error(f"å¤„ç†ä¸Šä¸€æ¬¡è¿­ä»£æ•°æ®çš„åŒé‡è½¬ä¹‰JSONå¤±è´¥: {str(e)}")
                    # ä¿æŒåŸæ ·

        log(f"æˆåŠŸåŠ è½½æµ‹è¯•ç”¨ä¾‹æ•°æ®", important=True)
    except Exception as e:
        log_error("åŠ è½½æ•°æ®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯", e)
        end_logging()
        return {
            "success": False,
            "error": f"åŠ è½½æ•°æ®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}",
            "traceback": traceback.format_exc()
        }

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    try:
        os.makedirs(os.path.dirname(report_file), exist_ok=True)
        os.makedirs(os.path.dirname(report_json_file), exist_ok=True)
    except Exception as e:
        log_error("åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥", e)
        end_logging()
        return {
            "success": False,
            "error": f"åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: {str(e)}"
        }

    # åˆ›å»ºaiohttpä¼šè¯ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ä¼˜åŒ–å‚æ•°è®¾ç½®
    # ç”Ÿæˆå”¯ä¸€çš„ä¼šè¯IDï¼Œç¡®ä¿æ¯æ¬¡è¯„æµ‹ä½¿ç”¨æ–°çš„ä¼šè¯
    session_id = str(uuid.uuid4())
    log(f"åˆ›å»ºæ–°çš„è¯„æµ‹ä¼šè¯: {session_id}", important=True)

    timeout = aiohttp.ClientTimeout(total=AIOHTTP_TIMEOUT)
    connector = aiohttp.TCPConnector(
        limit=AIOHTTP_CONNECTOR_LIMIT,
        ttl_dns_cache=AIOHTTP_CONNECTOR_TTL,
        force_close=True,  # å¼ºåˆ¶å…³é—­è¿æ¥ï¼Œé¿å…å¤ç”¨
        enable_cleanup_closed=True  # è‡ªåŠ¨æ¸…ç†å…³é—­çš„è¿æ¥
    )

    async with aiohttp.ClientSession(
            timeout=timeout,
            connector=connector,
            headers={"Connection": "close", "X-Session-ID": session_id}  # ä¿®æ”¹ä¸ºä¸ä¿æŒè¿æ¥
    ) as session:
        try:
            # 2. æ ¼å¼åŒ–æµ‹è¯•ç”¨ä¾‹ - å¹¶è¡Œæ‰§è¡Œ
            log("å¼€å§‹æ ¼å¼åŒ–æµ‹è¯•ç”¨ä¾‹", important=True)

            # åˆ›å»ºæ ¼å¼åŒ–ä»»åŠ¡åˆ—è¡¨
            format_tasks = [
                format_test_cases(session, ai_cases_raw_text, "AI"),
                format_test_cases(session, golden_cases_raw_text, "Golden")
            ]
            
            # å¦‚æœå¯ç”¨è¿­ä»£å¯¹æ¯”ï¼Œæ·»åŠ æ ¼å¼åŒ–ä¸Šä¸€æ¬¡è¿­ä»£æ•°æ®çš„ä»»åŠ¡
            if is_iteration and prev_iteration_raw_text:
                format_tasks.append(format_test_cases(session, prev_iteration_raw_text, "Previous"))

            # å¹¶è¡Œæ‰§è¡Œæ ¼å¼åŒ–ä»»åŠ¡
            formatted_results = await asyncio.gather(*format_tasks)
            
            # è§£æç»“æœ
            if is_iteration and prev_iteration_raw_text:
                formatted_ai_cases, formatted_golden_cases, formatted_prev_iteration = formatted_results
            else:
                formatted_ai_cases, formatted_golden_cases = formatted_results
                formatted_prev_iteration = None

            if not formatted_ai_cases:
                log_error("æ ¼å¼åŒ–AIæµ‹è¯•ç”¨ä¾‹å¤±è´¥ï¼Œé€€å‡ºè¯„æµ‹")
                end_logging()
                return {
                    "success": False,
                    "error": "æ ¼å¼åŒ–AIæµ‹è¯•ç”¨ä¾‹å¤±è´¥"
                }

            # ä¿å­˜æ ¼å¼åŒ–åçš„AIæµ‹è¯•ç”¨ä¾‹ï¼ˆä½¿ç”¨ä¼šè¯å”¯ä¸€æ–‡ä»¶åï¼‰
            try:
                os.makedirs(os.path.dirname(formatted_ai_cases_file), exist_ok=True)
                with open(formatted_ai_cases_file, 'w', encoding='utf-8') as f:
                    json.dump(formatted_ai_cases, f, ensure_ascii=False, indent=2)
                log(f"æ ¼å¼åŒ–åçš„AIæµ‹è¯•ç”¨ä¾‹å·²ä¿å­˜åˆ° {formatted_ai_cases_file}", important=True)
            except Exception as e:
                log_error(f"ä¿å­˜æ ¼å¼åŒ–åçš„AIæµ‹è¯•ç”¨ä¾‹åˆ° {formatted_ai_cases_file} å¤±è´¥", e)
                # ç»§ç»­æ‰§è¡Œï¼Œä¸ä¸­æ–­æµç¨‹

            if not formatted_golden_cases:
                log_error("æ ¼å¼åŒ–é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹å¤±è´¥ï¼Œé€€å‡ºè¯„æµ‹")
                end_logging()
                return {
                    "success": False,
                    "error": "æ ¼å¼åŒ–é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹å¤±è´¥"
                }

            # ä¿å­˜æ ¼å¼åŒ–åçš„é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹ï¼ˆä½¿ç”¨ä¼šè¯å”¯ä¸€æ–‡ä»¶åï¼‰
            try:
                os.makedirs(os.path.dirname(formatted_golden_cases_file), exist_ok=True)
                with open(formatted_golden_cases_file, 'w', encoding='utf-8') as f:
                    json.dump(formatted_golden_cases, f, ensure_ascii=False, indent=2)
                log(f"æ ¼å¼åŒ–åçš„é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹å·²ä¿å­˜åˆ° {formatted_golden_cases_file}", important=True)
            except Exception as e:
                log_error(f"ä¿å­˜æ ¼å¼åŒ–åçš„é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹åˆ° {formatted_golden_cases_file} å¤±è´¥", e)
                # ç»§ç»­æ‰§è¡Œï¼Œä¸ä¸­æ–­æµç¨‹
                
            # å¦‚æœå¯ç”¨è¿­ä»£å¯¹æ¯”ï¼Œä¿å­˜æ ¼å¼åŒ–åçš„ä¸Šä¸€æ¬¡è¿­ä»£æµ‹è¯•ç”¨ä¾‹
            if is_iteration and formatted_prev_iteration and formatted_prev_iteration_file:
                try:
                    with open(formatted_prev_iteration_file, 'w', encoding='utf-8') as f:
                        json.dump(formatted_prev_iteration, f, ensure_ascii=False, indent=2)
                    log(f"æ ¼å¼åŒ–åçš„ä¸Šä¸€æ¬¡è¿­ä»£æµ‹è¯•ç”¨ä¾‹å·²ä¿å­˜åˆ° {formatted_prev_iteration_file}", important=True)
                except Exception as e:
                    log_error(f"ä¿å­˜æ ¼å¼åŒ–åçš„ä¸Šä¸€æ¬¡è¿­ä»£æµ‹è¯•ç”¨ä¾‹åˆ° {formatted_prev_iteration_file} å¤±è´¥", e)
                    # ç»§ç»­æ‰§è¡Œï¼Œä¸ä¸­æ–­æµç¨‹

            # 3. è¯„æµ‹æµ‹è¯•ç”¨ä¾‹å’Œç”ŸæˆæŠ¥å‘Š - å¹¶è¡Œæ‰§è¡Œ
            log("å¼€å§‹è¯„æµ‹æµ‹è¯•ç”¨ä¾‹å’Œå‡†å¤‡æŠ¥å‘Šç”Ÿæˆ", important=True)
            # æ·»åŠ å°å»¶è¿Ÿï¼Œç¡®ä¿æ—¥å¿—é¡ºåº
            await asyncio.sleep(0.05)

            # å¯åŠ¨è¯„æµ‹ä»»åŠ¡
            evaluation_task = asyncio.create_task(
                evaluate_test_cases(
                    session, 
                    formatted_ai_cases, 
                    formatted_golden_cases,
                    is_iteration=is_iteration,
                    prev_iteration_cases=formatted_prev_iteration
                )
            )

            # ç­‰å¾…è¯„æµ‹å®Œæˆ
            evaluation_result = await evaluation_task

            if not evaluation_result:
                log_error("è¯„æµ‹æµ‹è¯•ç”¨ä¾‹å¤±è´¥ï¼Œé€€å‡ºè¯„æµ‹")
                end_logging()
                return {
                    "success": False,
                    "error": "è¯„æµ‹æµ‹è¯•ç”¨ä¾‹å¤±è´¥"
                }

            # ä¿å­˜JSONæ ¼å¼çš„è¯„æµ‹ç»“æœ
            try:
                # ç¡®ä¿JSONæ–‡ä»¶ä¿å­˜åœ¨æ­£ç¡®çš„ç›®å½•
                json_file_dir = os.path.dirname(report_json_file)
                os.makedirs(json_file_dir, exist_ok=True)
                
                with open(report_json_file, 'w', encoding='utf-8') as f:
                    json.dump(evaluation_result, f, ensure_ascii=False, indent=2)
                log(f"JSONæ ¼å¼çš„è¯„æµ‹ç»“æœå·²ä¿å­˜åˆ° {report_json_file}", important=True)
                # æ·»åŠ å°å»¶è¿Ÿï¼Œç¡®ä¿æ—¥å¿—é¡ºåº
                await asyncio.sleep(0.05)
            except Exception as e:
                log_error(f"ä¿å­˜JSONæ ¼å¼çš„è¯„æµ‹ç»“æœåˆ° {report_json_file} å¤±è´¥", e)
                # ç»§ç»­æ‰§è¡Œï¼Œä¸ä¸­æ–­æµç¨‹

            # 4. ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Š
            log("å¼€å§‹ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š", important=True)
            # æ·»åŠ å°å»¶è¿Ÿï¼Œç¡®ä¿æ—¥å¿—é¡ºåº
            await asyncio.sleep(0.05)

            # è°ƒç”¨evaluate_and_generate_reportå‡½æ•°ï¼Œä¼ é€’è¿­ä»£å‚æ•°å’Œå·²æœ‰çš„è¯„æµ‹ç»“æœ
            report_result = await evaluate_and_generate_report(
                session, 
                formatted_ai_cases, 
                formatted_golden_cases,
                report_file,
                is_iteration=is_iteration,
                prev_iteration_cases=formatted_prev_iteration,
                evaluation_result=evaluation_result  # ä¼ é€’å·²æœ‰çš„è¯„æµ‹ç»“æœ
            )

            if not report_result.get("success", False):
                log_error("ç”ŸæˆæŠ¥å‘Šå¤±è´¥", important=True)
                # ç»§ç»­æ‰§è¡Œï¼Œä¸ä¸­æ–­æµç¨‹

            # å¤„ç†å¯èƒ½çš„MarkdownæŠ¥å‘Šæ ¼å¼é—®é¢˜
            markdown_report = None
            markdown_report_iteration = None
            
            # æå–æ ‡å‡†æŠ¥å‘Š
            if report_result.get("report"):
                markdown_report = report_result["report"]
            elif report_result.get("markdown_report"):
                markdown_report = report_result["markdown_report"]
                
            # æå–è¿­ä»£æŠ¥å‘Š
            if report_result.get("report_iteration"):
                markdown_report_iteration = report_result["report_iteration"]
                
            # å¤„ç†æ ‡å‡†æŠ¥å‘Šæ ¼å¼
            if markdown_report:
                # å¦‚æœæ˜¯å­—å…¸æ ¼å¼çš„ç»“æœï¼Œæå–æ–‡æœ¬å†…å®¹
                if isinstance(markdown_report, dict) and "text" in markdown_report:
                    markdown_report = markdown_report["text"]

                # æ¸…ç†MarkdownæŠ¥å‘Šï¼Œç¡®ä¿æ²¡æœ‰"markdown"å‰ç¼€
                if markdown_report.strip().startswith("markdown"):
                    markdown_report = markdown_report.strip().replace("markdown", "", 1).strip()
                    log("å·²åˆ é™¤æœ€ç»ˆæŠ¥å‘Šä¸­çš„'markdown'å‰ç¼€", important=True)

                # å¤„ç†å¯èƒ½çš„ç©ºè¡Œå‰ç¼€
                if markdown_report.startswith("\n") and not markdown_report.strip().startswith("#"):
                    markdown_report = markdown_report.lstrip()
                    log("å·²åˆ é™¤æœ€ç»ˆæŠ¥å‘Šä¸­çš„å‰å¯¼ç©ºè¡Œ", important=True)

                # å¤„ç†å¯èƒ½åŒ…å«çš„ä»£ç å—æ ‡è®°
                if "```markdown" in markdown_report:
                    # æå–ä»£ç å—å†…å®¹
                    try:
                        markdown_report = markdown_report.split("```markdown")[1].split("```")[0].strip()
                        log("å·²ä»markdownä»£ç å—ä¸­æå–å†…å®¹", important=True)
                    except:
                        log_error("å¤„ç†markdownä»£ç å—å¤±è´¥ï¼Œä¿ç•™åŸå§‹å†…å®¹")
                elif "```" in markdown_report and not "```json" in markdown_report:
                    # å¯èƒ½æ˜¯é€šç”¨ä»£ç å—
                    try:
                        parts = markdown_report.split("```")
                        if len(parts) >= 3 and len(parts[0].strip()) == 0:
                            # å¦‚æœç¬¬ä¸€ä¸ªåˆ†å‰²æ˜¯ç©ºçš„ï¼Œå–ç¬¬äºŒä¸ªéƒ¨åˆ†ï¼ˆä»£ç å—å†…å®¹ï¼‰
                            markdown_report = parts[1].strip()
                            log("å·²ä»ä»£ç å—ä¸­æå–å†…å®¹", important=True)
                    except:
                        log_error("å¤„ç†ä»£ç å—å¤±è´¥ï¼Œä¿ç•™åŸå§‹å†…å®¹")
            
            # å¯¹è¿­ä»£æŠ¥å‘Šåšç±»ä¼¼çš„å¤„ç†
            if markdown_report_iteration:
                # å¦‚æœæ˜¯å­—å…¸æ ¼å¼çš„ç»“æœï¼Œæå–æ–‡æœ¬å†…å®¹
                if isinstance(markdown_report_iteration, dict) and "text" in markdown_report_iteration:
                    markdown_report_iteration = markdown_report_iteration["text"]

                # æ¸…ç†MarkdownæŠ¥å‘Šï¼Œç¡®ä¿æ²¡æœ‰"markdown"å‰ç¼€
                if markdown_report_iteration.strip().startswith("markdown"):
                    markdown_report_iteration = markdown_report_iteration.strip().replace("markdown", "", 1).strip()
                    log("å·²åˆ é™¤è¿­ä»£æŠ¥å‘Šä¸­çš„'markdown'å‰ç¼€", important=True)

                # å¤„ç†å¯èƒ½çš„ç©ºè¡Œå‰ç¼€
                if markdown_report_iteration.startswith("\n") and not markdown_report_iteration.strip().startswith("#"):
                    markdown_report_iteration = markdown_report_iteration.lstrip()
                    log("å·²åˆ é™¤è¿­ä»£æŠ¥å‘Šä¸­çš„å‰å¯¼ç©ºè¡Œ", important=True)

                # å¤„ç†å¯èƒ½åŒ…å«çš„ä»£ç å—æ ‡è®°
                if "```markdown" in markdown_report_iteration:
                    # æå–ä»£ç å—å†…å®¹
                    try:
                        markdown_report_iteration = markdown_report_iteration.split("```markdown")[1].split("```")[0].strip()
                        log("å·²ä»è¿­ä»£æŠ¥å‘Šmarkdownä»£ç å—ä¸­æå–å†…å®¹", important=True)
                    except:
                        log_error("å¤„ç†è¿­ä»£æŠ¥å‘Šmarkdownä»£ç å—å¤±è´¥ï¼Œä¿ç•™åŸå§‹å†…å®¹")
                elif "```" in markdown_report_iteration and not "```json" in markdown_report_iteration:
                    # å¯èƒ½æ˜¯é€šç”¨ä»£ç å—
                    try:
                        parts = markdown_report_iteration.split("```")
                        if len(parts) >= 3 and len(parts[0].strip()) == 0:
                            # å¦‚æœç¬¬ä¸€ä¸ªåˆ†å‰²æ˜¯ç©ºçš„ï¼Œå–ç¬¬äºŒä¸ªéƒ¨åˆ†ï¼ˆä»£ç å—å†…å®¹ï¼‰
                            markdown_report_iteration = parts[1].strip()
                            log("å·²ä»è¿­ä»£æŠ¥å‘Šä»£ç å—ä¸­æå–å†…å®¹", important=True)
                    except:
                        log_error("å¤„ç†è¿­ä»£æŠ¥å‘Šä»£ç å—å¤±è´¥ï¼Œä¿ç•™åŸå§‹å†…å®¹")

                # æ£€æŸ¥å¹¶ä¿®å¤Mermaidå›¾è¡¨
                try:
                    # ç¡®ä¿mermaidå›¾è¡¨æ ¼å¼æ­£ç¡®
                    if "```mermaid" not in markdown_report:
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«Mermaidå›¾è¡¨å…³é”®è¯
                        chart_keywords = [
                            "flowchart ", "graph ", "pie", "piechart", "bar", "barchart",
                            "sequenceDiagram", "classDiagram", "stateDiagram", "gantt"
                        ]

                        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿®å¤å›¾è¡¨è¯­æ³•
                        needs_fix = False
                        for keyword in chart_keywords:
                            if f"\n{keyword}" in markdown_report:
                                needs_fix = True
                                break

                        if needs_fix:
                            # æ›´æ–°å›¾è¡¨è¯­æ³• - ä½¿ç”¨æ›´ç°ä»£çš„å‘½å
                            replacements = {
                                "graph TD": "flowchart TD",
                                "graph LR": "flowchart LR",
                                "pie": "piechart",
                                "bar": "barchart"
                            }

                            for old, new in replacements.items():
                                markdown_report = markdown_report.replace(f"\n{old}", f"\n{new}")

                            # ä¿®å¤å›¾è¡¨ç»“æ„
                            for chart_type in chart_keywords:
                                pattern = f"\n{chart_type}"
                                if pattern in markdown_report:
                                    parts = markdown_report.split(pattern)
                                    fixed_parts = []
                                    for i, part in enumerate(parts):
                                        if i == 0:
                                            fixed_parts.append(part)
                                        else:
                                            # æŸ¥æ‰¾è¿™éƒ¨åˆ†å†…å®¹çš„ç»“æŸä½ç½®
                                            lines = part.split("\n")
                                            end_index = 0
                                            for j, line in enumerate(lines):
                                                if line.strip() == "" and j > 0:
                                                    end_index = j
                                                    break

                                            if end_index > 0:
                                                chart_content = "\n".join(lines[:end_index])
                                                rest_content = "\n".join(lines[end_index:])
                                                fixed_parts.append(
                                                    f"\n```mermaid\n{chart_type}{chart_content}\n```\n{rest_content}")
                                            else:
                                                fixed_parts.append(f"\n```mermaid\n{chart_type}{part}\n```")

                                    markdown_report = "".join(fixed_parts)

                            log("å·²ä¿®å¤Mermaidå›¾è¡¨è¯­æ³•", important=True)

                            # ç¬¬äºŒé˜¶æ®µä¿®å¤ - ç¡®ä¿ä½¿ç”¨é€šç”¨å›¾è¡¨è¯­æ³•
                            log("æ­£åœ¨å°†å›¾è¡¨è½¬æ¢ä¸ºæ›´é€šç”¨çš„è¯­æ³•æ ¼å¼...", important=True)
                            backward_replacements = {
                                "flowchart TD": "graph TD",
                                "flowchart LR": "graph LR",
                                "piechart": "pie",
                                "barchart": "bar"
                            }

                            for new_syntax, old_syntax in backward_replacements.items():
                                markdown_report = markdown_report.replace(new_syntax, old_syntax)

                            log("å·²å®Œæˆå›¾è¡¨è¯­æ³•é€šç”¨æ€§è½¬æ¢", important=True)

                    # ä¿®å¤é¥¼å›¾ä¸­çš„å†’å·è¯­æ³•é”™è¯¯
                    import re
                    log("æ­£åœ¨ä¿®å¤é¥¼å›¾è¯­æ³•é”™è¯¯...", important=True)

                    # æŸ¥æ‰¾æ‰€æœ‰é¥¼å›¾å†…å®¹
                    pie_chart_pattern = r"```mermaid\s*\npie[\s\S]*?```"
                    pie_charts = re.findall(pie_chart_pattern, markdown_report)

                    for pie_chart in pie_charts:
                        # ä¿®å¤å†’å·è¯­æ³•é”™è¯¯ï¼ˆå°†å…¨è§’å†’å· "ï¼š" æ›¿æ¢ä¸ºåŠè§’å†’å· ":" ï¼‰
                        fixed_chart = pie_chart.replace("ï¼š", ":")
                        # ä¿®å¤ä¸­æ–‡åŒå¼•å·é—®é¢˜ï¼ˆå°†ä¸­æ–‡åŒå¼•å· "" æ›¿æ¢ä¸ºè‹±æ–‡åŒå¼•å· ""ï¼‰
                        fixed_chart = fixed_chart.replace(""", "\"").replace(""", "\"")
                        # ä¿®å¤å†’å·å‰åçš„ç©ºæ ¼é—®é¢˜ï¼ˆå¦‚"é”® : å€¼"æ”¹ä¸º"é”®": å€¼ï¼‰
                        fixed_chart = re.sub(r'("[^"]+")(\s*):(\s*)(\d+\.?\d*)', r'\1: \4', fixed_chart)
                        # åº”ç”¨ä¿®å¤åçš„å›¾è¡¨
                        markdown_report = markdown_report.replace(pie_chart, fixed_chart)

                    log("å·²ä¿®å¤é¥¼å›¾è¯­æ³•é”™è¯¯å’ŒåŒå¼•å·é—®é¢˜", important=True)

                    # ä¿®å¤åˆå¹¶å»ºè®®å›¾ä¸­çš„åŒå¼•å·è¯­æ³•é”™è¯¯
                    log("æ­£åœ¨ä¿®å¤åˆå¹¶å»ºè®®å›¾ä¸­çš„åŒå¼•å·è¯­æ³•é”™è¯¯...", important=True)
                    merge_chart_pattern = r"```mermaid\s*\ngraph LR[\s\S]*?```"
                    merge_charts = re.findall(merge_chart_pattern, markdown_report)

                    for merge_chart in merge_charts:
                        # æŸ¥æ‰¾å¹¶ä¿®å¤æ ¼å¼ä¸º ID["æ–‡æœ¬"] çš„æ¨¡å¼
                        node_pattern = r'(\w+(?:-\w+)*)\["([^"]+)"\]'
                        fixed_chart = re.sub(node_pattern, r'\1[\2]', merge_chart)
                        # åº”ç”¨ä¿®å¤åçš„å›¾è¡¨
                        markdown_report = markdown_report.replace(merge_chart, fixed_chart)

                    log("å·²ä¿®å¤åˆå¹¶å»ºè®®å›¾ä¸­çš„åŒå¼•å·è¯­æ³•é”™è¯¯", important=True)

                    # ä¿®å¤è¯„æµ‹æµç¨‹æ¡†æ¶å›¾ä¸­çš„å†’å·è¯­æ³•é”™è¯¯
                    log("æ­£åœ¨ä¿®å¤è¯„æµ‹æµç¨‹æ¡†æ¶å›¾ä¸­çš„è¯­æ³•é”™è¯¯...", important=True)
                    framework_chart_pattern = r"```mermaid\s*\ngraph TD[\s\S]*?```"
                    framework_charts = re.findall(framework_chart_pattern, markdown_report)

                    for framework_chart in framework_charts:
                        # ä¿®å¤å…¨è§’å†’å·ä¸ºåŠè§’å†’å·
                        fixed_chart = framework_chart.replace("ï¼š", ":")
                        # ä¿®å¤å†’å·å‰åçš„ç©ºæ ¼é—®é¢˜
                        fixed_chart = re.sub(r'(\w+)(\s*):(\s*)(\w+)', r'\1: \4', fixed_chart)
                        # åº”ç”¨ä¿®å¤åçš„å›¾è¡¨
                        markdown_report = markdown_report.replace(framework_chart, fixed_chart)

                    log("å·²ä¿®å¤è¯„æµ‹æµç¨‹æ¡†æ¶å›¾ä¸­çš„è¯­æ³•é”™è¯¯", important=True)

                    # ä¿®å¤æ‰€æœ‰å…¶ä»–mermaidå›¾è¡¨ä¸­å¯èƒ½å­˜åœ¨çš„å†’å·é—®é¢˜
                    log("æ­£åœ¨ä¿®å¤æ‰€æœ‰mermaidå›¾è¡¨ä¸­çš„å†’å·å’ŒåŒå¼•å·é—®é¢˜...", important=True)
                    all_mermaid_pattern = r"```mermaid[\s\S]*?```"
                    all_mermaid_charts = re.findall(all_mermaid_pattern, markdown_report)

                    for chart in all_mermaid_charts:
                        # ä¿®å¤å…¨è§’å†’å·ä¸ºåŠè§’å†’å·
                        fixed_chart = chart.replace("ï¼š", ":")
                        # ä¿®å¤ä¸­æ–‡åŒå¼•å·é—®é¢˜
                        fixed_chart = fixed_chart.replace(""", "\"").replace(""", "\"")
                        # åº”ç”¨ä¿®å¤åçš„å›¾è¡¨
                        if fixed_chart != chart:
                            markdown_report = markdown_report.replace(chart, fixed_chart)

                    log("å·²ä¿®å¤æ‰€æœ‰mermaidå›¾è¡¨ä¸­çš„å†’å·å’ŒåŒå¼•å·é—®é¢˜", important=True)

                    # ç§»é™¤å®‰å…¨ä¸ç»æµæ€§éƒ¨åˆ†çš„å›¾è¡¨
                    import re
                    log("æ­£åœ¨ç§»é™¤å®‰å…¨ä¸ç»æµæ€§éƒ¨åˆ†çš„å›¾è¡¨...", important=True)

                    # ç§»é™¤å®‰å…¨ä¸ç»æµæ€§éƒ¨åˆ†çš„å›¾è¡¨
                    # åŒ¹é…æ¨¡å¼ï¼šä»"### ğŸ›¡ï¸ å®‰å…¨ä¸ç»æµæ€§"æˆ–ç±»ä¼¼æ ‡é¢˜å¼€å§‹ï¼Œåˆ°ä¸‹ä¸€ä¸ªå›¾è¡¨ç»“æŸ
                    security_chart_pattern = r"(### (?:ğŸ›¡ï¸ )?å®‰å…¨ä¸ç»æµæ€§.*?)(```mermaid[\s\S]*?```)"
                    markdown_report = re.sub(security_chart_pattern, r"\1", markdown_report)

                    # ç§»é™¤å¯èƒ½å­˜åœ¨çš„å¤šä½™ç©ºè¡Œ
                    markdown_report = re.sub(r'\n{3,}', '\n\n', markdown_report)

                    log("å·²ç§»é™¤å®‰å…¨ä¸ç»æµæ€§éƒ¨åˆ†çš„å›¾è¡¨", important=True)

                except Exception as e:
                    log_error(f"ä¿®å¤Mermaidå›¾è¡¨æ—¶å‡ºé”™: {e}")
                    # ç»§ç»­å¤„ç†ï¼Œä¸ä¸­æ–­æµç¨‹

                # æ›´æ–°é¡µè„šä¸ºå®æ—¶æ—¶é—´å’Œè‡ªå®šä¹‰è¯„ä¼°ä¸­å¿ƒåç§°
                try:
                    from datetime import datetime
                    # ç¡®ä¿ä½¿ç”¨å®æ—¶æ—¶é—´
                    current_time = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")
                    new_footer = f"**ç”Ÿæˆæ—¶é—´ï¼š{current_time} â€¢ gogogoå‡ºå‘å–½è¯„ä¼°ä¸­å¿ƒ**"

                    # æŸ¥æ‰¾å¹¶æ›¿æ¢åŸæœ‰é¡µè„šï¼Œä½¿ç”¨æ›´å®½æ¾çš„æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ä»»ä½•æ ¼å¼çš„æ—¥æœŸã€å ä½ç¬¦æˆ–æ—¶é—´æˆ³
                    import re
                    footer_pattern = r"\*\*ç”Ÿæˆæ—¶é—´ï¼š(.*?)(?:â€¢|Â·|\*) *gogogoå‡ºå‘å–½è¯„ä¼°ä¸­å¿ƒ\*\*"
                    placeholder_patterns = [
                        r"\*\*ç”Ÿæˆæ—¶é—´ï¼šDATETIME_PLACEHOLDER â€¢ gogogoå‡ºå‘å–½è¯„ä¼°ä¸­å¿ƒ\*\*",
                        r"\*\*ç”Ÿæˆæ—¶é—´ï¼šDATETIME_PLACEHOLDER(?:â€¢|Â·|\*) *gogogoå‡ºå‘å–½è¯„ä¼°ä¸­å¿ƒ\*\*",
                        r"\*\*ç”Ÿæˆæ—¶é—´ï¼š<.*?>(?:â€¢|Â·|\*) *gogogoå‡ºå‘å–½è¯„ä¼°ä¸­å¿ƒ\*\*"
                    ]
                    
                    # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰æ˜ç¡®çš„å ä½ç¬¦
                    placeholder_found = False
                    for pattern in placeholder_patterns:
                        if re.search(pattern, markdown_report):
                            markdown_report = re.sub(pattern, new_footer, markdown_report)
                            placeholder_found = True
                            log("å·²æ›¿æ¢é¡µè„šä¸­çš„æ˜ç¡®å ä½ç¬¦ä¸ºå®æ—¶æ—¶é—´", important=True)
                            break
                    
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„å ä½ç¬¦ï¼Œå°è¯•ä½¿ç”¨é€šç”¨æ¨¡å¼
                    if not placeholder_found and re.search(footer_pattern, markdown_report):
                        markdown_report = re.sub(footer_pattern, new_footer, markdown_report)
                        log("å·²æ›¿æ¢é¡µè„šä¸­çš„æ—¥æœŸä¸ºå®æ—¶æ—¶é—´", important=True)
                    elif not placeholder_found:
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é¡µè„šï¼Œåˆ™æ·»åŠ åˆ°æŠ¥å‘Šæœ«å°¾
                        markdown_report = markdown_report.rstrip() + "\n\n---\n" + new_footer + "\n"
                        log("æœªæ‰¾åˆ°é¡µè„šï¼Œå·²æ·»åŠ å¸¦æœ‰å®æ—¶æ—¶é—´çš„é¡µè„š", important=True)

                    log("å·²æ›´æ–°æŠ¥å‘Šé¡µè„šä¸ºå®æ—¶æ—¶é—´å’Œè‡ªå®šä¹‰è¯„ä¼°ä¸­å¿ƒåç§°", important=True)
                except Exception as e:
                    log_error(f"æ›´æ–°é¡µè„šæ—¶å‡ºé”™: {e}")
                    # ç»§ç»­å¤„ç†ï¼Œä¸ä¸­æ–­æµç¨‹

            # ä¿å­˜Markdownæ ¼å¼çš„æŠ¥å‘Š
            try:
                # ç¡®ä¿markdown_reportæ˜¯å­—ç¬¦ä¸²
                if not isinstance(markdown_report, str):
                    markdown_report = str(markdown_report)

                # åœ¨ä¿å­˜å‰è¿›è¡Œæœ€ç»ˆçš„å ä½ç¬¦æ£€æŸ¥å’Œæ›¿æ¢
                from datetime import datetime
                current_time = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")
                new_footer = f"**ç”Ÿæˆæ—¶é—´ï¼š{current_time} â€¢ gogogoå‡ºå‘å–½è¯„ä¼°ä¸­å¿ƒ**"

                import re
                placeholder_patterns = [
                    r"\*\*ç”Ÿæˆæ—¶é—´ï¼šDATETIME_PLACEHOLDER â€¢ gogogoå‡ºå‘å–½è¯„ä¼°ä¸­å¿ƒ\*\*",
                    r"\*\*ç”Ÿæˆæ—¶é—´ï¼šDATETIME_PLACEHOLDER(?:â€¢|Â·|\*) *gogogoå‡ºå‘å–½è¯„ä¼°ä¸­å¿ƒ\*\*",
                    r"\*\*ç”Ÿæˆæ—¶é—´ï¼š<.*?>(?:â€¢|Â·|\*) *gogogoå‡ºå‘å–½è¯„ä¼°ä¸­å¿ƒ\*\*"
                ]

                # æ£€æŸ¥å¹¶æ›¿æ¢å ä½ç¬¦
                placeholder_found = False
                for pattern in placeholder_patterns:
                    if re.search(pattern, markdown_report):
                        markdown_report = re.sub(pattern, new_footer, markdown_report)
                        placeholder_found = True
                        log("ä¿å­˜å‰å·²æ›¿æ¢æŠ¥å‘Šä¸­çš„å ä½ç¬¦ä¸ºå®æ—¶æ—¶é—´", important=True)
                        break

                if not placeholder_found:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å ä½ç¬¦ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–æ ¼å¼çš„æ—¶é—´æˆ³éœ€è¦æ›´æ–°
                    footer_pattern = r"\*\*ç”Ÿæˆæ—¶é—´ï¼š(.*?)(?:â€¢|Â·|\*) *gogogoå‡ºå‘å–½è¯„ä¼°ä¸­å¿ƒ\*\*"
                    if re.search(footer_pattern, markdown_report):
                        markdown_report = re.sub(footer_pattern, new_footer, markdown_report)
                        log("ä¿å­˜å‰å·²æ›´æ–°æŠ¥å‘Šä¸­çš„æ—¶é—´æˆ³ä¸ºå®æ—¶æ—¶é—´", important=True)
                    else:
                        log("ä¿å­˜å‰æœªåœ¨æŠ¥å‘Šä¸­æ‰¾åˆ°æ—¶é—´æˆ³ï¼Œå°†æ·»åŠ é¡µè„š", level="WARNING")
                        markdown_report = markdown_report.rstrip() + "\n\n---\n" + new_footer + "\n"

                # ç¡®ä¿ç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(report_file), exist_ok=True)

                # ä½¿ç”¨utf-8ç¼–ç ä¿å­˜æ–‡ä»¶
                with open(report_file, 'w', encoding='utf-8') as f:
                    f.write(markdown_report)

                log(f"Markdownæ ¼å¼çš„è¯„æµ‹æŠ¥å‘Šå·²ä¿å­˜åˆ° {report_file}", important=True)
                # æ·»åŠ å°å»¶è¿Ÿï¼Œç¡®ä¿æ—¥å¿—é¡ºåº
                await asyncio.sleep(0.05)
            except Exception as e:
                log_error(f"ä¿å­˜Markdownæ ¼å¼çš„è¯„æµ‹æŠ¥å‘Šåˆ° {report_file} å¤±è´¥", e)
                # ç»§ç»­æ‰§è¡Œï¼Œä¸ä¸­æ–­æµç¨‹

            # ç»“åˆè¯„æµ‹ç»“æœå’Œç”Ÿæˆçš„Markdownæ ¼å¼æŠ¥å‘Šè¿”å›æœ€ç»ˆç»“æœ
            result = {
                "success": True,
                "evaluation_result": evaluation_result,
                "files": {
                    "report_md": report_file,
                    "report_json": report_json_file
                }
            }

            # æ·»åŠ æ ‡å‡†æŠ¥å‘Š
            if markdown_report:
                result["report"] = markdown_report
                result["markdown_report"] = markdown_report
                log("å·²æ·»åŠ æ ‡å‡†æŠ¥å‘Šåˆ°ç»“æœ", important=True)

            # æ·»åŠ è¿­ä»£æŠ¥å‘Š
            if is_iteration and markdown_report_iteration:
                result["report_iteration"] = markdown_report_iteration
                log(f"å·²æ·»åŠ è¿­ä»£æŠ¥å‘Šåˆ°ç»“æœï¼Œé•¿åº¦: {len(markdown_report_iteration)}", important=True)
            elif is_iteration:
                log("è¿­ä»£æ¨¡å¼å·²å¯ç”¨ä½†è¿­ä»£æŠ¥å‘Šä¸ºç©ºï¼Œæœªèƒ½æ·»åŠ è¿­ä»£æŠ¥å‘Š", level="WARNING")
            
            # è®°å½•æœ€ç»ˆè¿”å›çš„å­—æ®µ
            log(f"æœ€ç»ˆç»“æœåŒ…å«ä»¥ä¸‹å­—æ®µ: {', '.join(result.keys())}", important=True)

            log("æµ‹è¯•ç”¨ä¾‹è¯„æµ‹æµç¨‹å®Œæˆï¼", important=True)
            # æ·»åŠ å°å»¶è¿Ÿï¼Œç¡®ä¿æ—¥å¿—é¡ºåº
            await asyncio.sleep(0.05)
            end_logging()

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                if os.path.exists(formatted_ai_cases_file):
                    os.remove(formatted_ai_cases_file)
                if os.path.exists(formatted_golden_cases_file):
                    os.remove(formatted_golden_cases_file)
                if formatted_prev_iteration_file and os.path.exists(formatted_prev_iteration_file):
                    os.remove(formatted_prev_iteration_file)
                log("å·²æ¸…ç†ä¸´æ—¶æ ¼å¼åŒ–æ–‡ä»¶", level="INFO")
            except Exception as e:
                log_error(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}", level="WARNING")

            return result
        except aiohttp.ClientError as e:
            log_error("APIè¯·æ±‚é”™è¯¯", e)
            end_logging()
            return {
                "success": False,
                "error": f"APIè¯·æ±‚é”™è¯¯: {str(e)}",
                "error_type": "network_error"
            }
        except asyncio.TimeoutError as e:
            log_error("APIè¯·æ±‚è¶…æ—¶", {"error_message": "è¯·æ±‚è¶…æ—¶ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–æœåŠ¡å™¨å“åº”æ—¶é—´è¿‡é•¿"})
            end_logging()
            return {
                "success": False,
                "error": "APIè¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•",
                "error_type": "timeout"
            }
        except Exception as e:
            log_error("æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯", e)
            end_logging()
            return {
                "success": False,
                "error": str(e),
                "traceback": traceback.format_exc(),
                "error_type": "unknown"
            }


def main(ai_cases_file=None, golden_cases_file=None, is_iteration=False, prev_iteration_file=None):
    """
    å…¼å®¹åŸæœ‰å…¥å£ç‚¹çš„ä¸»å‡½æ•°

    :param ai_cases_file: AIæµ‹è¯•ç”¨ä¾‹æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    :param golden_cases_file: é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    :param is_iteration: æ˜¯å¦å¯ç”¨è¿­ä»£å‰åå¯¹æ¯”åŠŸèƒ½
    :param prev_iteration_file: ä¸Šä¸€æ¬¡è¿­ä»£çš„æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰ï¼Œä»…åœ¨is_iterationä¸ºtrueæ—¶æœ‰æ•ˆ
    """
    # å¦‚æœæ˜¯Windowså¹³å°ï¼Œéœ€è¦æ˜¾å¼è®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥
    if os.name == 'nt':
        log("è®¾ç½®Windowsäº‹ä»¶å¾ªç¯ç­–ç•¥")
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

    ai_cases_data = None
    golden_cases_data = None
    prev_iteration_data = None

    # å¦‚æœæä¾›äº†æ–‡ä»¶è·¯å¾„ï¼Œåˆ™ä»æŒ‡å®šæ–‡ä»¶è¯»å–æ•°æ®
    if ai_cases_file:
        try:
            with open(ai_cases_file, 'r', encoding='utf-8') as f:
                ai_cases_data = f.read()
            log(f"ä»æ–‡ä»¶ {ai_cases_file} è¯»å–AIæµ‹è¯•ç”¨ä¾‹æ•°æ®")
        except Exception as e:
            log_error(f"è¯»å–AIæµ‹è¯•ç”¨ä¾‹æ–‡ä»¶ {ai_cases_file} å¤±è´¥", e)
            return {"success": False, "error": f"è¯»å–AIæµ‹è¯•ç”¨ä¾‹æ–‡ä»¶å¤±è´¥: {e}"}

    if golden_cases_file:
        try:
            with open(golden_cases_file, 'r', encoding='utf-8') as f:
                golden_cases_data = f.read()
            log(f"ä»æ–‡ä»¶ {golden_cases_file} è¯»å–é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹æ•°æ®")
        except Exception as e:
            log_error(f"è¯»å–é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶ {golden_cases_file} å¤±è´¥", e)
            return {"success": False, "error": f"è¯»å–é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶å¤±è´¥: {e}"}
            
    if is_iteration and prev_iteration_file:
        try:
            with open(prev_iteration_file, 'r', encoding='utf-8') as f:
                prev_iteration_data = f.read()
            log(f"ä»æ–‡ä»¶ {prev_iteration_file} è¯»å–ä¸Šä¸€æ¬¡è¿­ä»£æµ‹è¯•ç”¨ä¾‹æ•°æ®")
        except Exception as e:
            log_error(f"è¯»å–ä¸Šä¸€æ¬¡è¿­ä»£æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶ {prev_iteration_file} å¤±è´¥", e)
            log("è¿­ä»£å‰åå¯¹æ¯”åŠŸèƒ½å°†è¢«ç¦ç”¨", level="WARNING")
            is_iteration = False

    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    return asyncio.run(async_main(ai_cases_data, golden_cases_data, is_iteration, prev_iteration_data))
