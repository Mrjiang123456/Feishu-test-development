import json
import aiohttp
from logger import log, log_error
from llm_api import async_call_llm
from analyzer import find_duplicate_test_cases
import re
import asyncio
import concurrent.futures
from config import MAX_CONCURRENT_REQUESTS, LLM_TEMPERATURE, LLM_TEMPERATURE_REPORT


async def evaluate_test_cases(session: aiohttp.ClientSession, ai_cases, golden_cases):
    """
    è¯„æµ‹æµ‹è¯•ç”¨ä¾‹è´¨é‡

    :param session: aiohttpä¼šè¯
    :param ai_cases: AIç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹
    :param golden_cases: é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹
    :return: è¯„æµ‹ç»“æœ
    """
    log("å¼€å§‹æµ‹è¯•ç”¨ä¾‹è¯„æµ‹", important=True)

    # æ·»åŠ å°å»¶è¿Ÿï¼Œç¡®ä¿æ—¥å¿—é¡ºåº
    await asyncio.sleep(0.1)

    # è·å–æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹
    ai_testcases = []
    golden_testcases = []

    # å®šä¹‰æ ¼å¼åŒ–å‡½æ•°ï¼Œä¾¿äºå¹¶è¡Œå¤„ç†
    def extract_ai_testcases(ai_cases):
        result = []
        # æå–AIæµ‹è¯•ç”¨ä¾‹ï¼Œé€‚é…æ–°çš„æ ¼å¼åŒ–ç»“æ„
        if isinstance(ai_cases, dict):
            if "testcases" in ai_cases and isinstance(ai_cases["testcases"], dict):
                # æ–°çš„ç»Ÿä¸€æ ¼å¼
                if "test_cases" in ai_cases["testcases"]:
                    # å¤„ç†test_caseså¯èƒ½æ˜¯å­—å…¸(åŒ…å«ä¸åŒç±»åˆ«çš„æµ‹è¯•ç”¨ä¾‹)çš„æƒ…å†µ
                    if isinstance(ai_cases["testcases"]["test_cases"], dict):
                        for category, cases in ai_cases["testcases"]["test_cases"].items():
                            if isinstance(cases, list):
                                for case in cases:
                                    if isinstance(case, dict):
                                        case["category"] = category
                                    result.append(case)
                    # å¤„ç†test_casesæ˜¯åˆ—è¡¨çš„æƒ…å†µ
                    elif isinstance(ai_cases["testcases"]["test_cases"], list):
                        result = ai_cases["testcases"]["test_cases"]
            elif "test_cases" in ai_cases:
                if isinstance(ai_cases["test_cases"], dict):
                    # æ—§æ ¼å¼ï¼Œåˆ†ç±»æµ‹è¯•ç”¨ä¾‹
                    for category, cases in ai_cases["test_cases"].items():
                        if isinstance(cases, list):
                            result.extend(cases)
                elif isinstance(ai_cases["test_cases"], list):
                    # æ—§æ ¼å¼ï¼Œç›´æ¥åˆ—è¡¨
                    result = ai_cases["test_cases"]
        return result

    def extract_golden_testcases(golden_cases):
        result = []
        # æå–é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹ï¼Œé€‚é…æ–°çš„æ ¼å¼åŒ–ç»“æ„
        if isinstance(golden_cases, dict):
            if "testcases" in golden_cases and isinstance(golden_cases["testcases"], dict):
                # æ–°çš„ç»Ÿä¸€æ ¼å¼
                if "test_cases" in golden_cases["testcases"]:
                    # å¤„ç†test_caseså¯èƒ½æ˜¯å­—å…¸(åŒ…å«ä¸åŒç±»åˆ«çš„æµ‹è¯•ç”¨ä¾‹)çš„æƒ…å†µ
                    if isinstance(golden_cases["testcases"]["test_cases"], dict):
                        for category, cases in golden_cases["testcases"]["test_cases"].items():
                            if isinstance(cases, list):
                                for case in cases:
                                    if isinstance(case, dict):
                                        case["category"] = category
                                    result.append(case)
                    # å¤„ç†test_casesæ˜¯åˆ—è¡¨çš„æƒ…å†µ
                    elif isinstance(golden_cases["testcases"]["test_cases"], list):
                        result = golden_cases["testcases"]["test_cases"]
            elif "test_cases" in golden_cases:
                if isinstance(golden_cases["test_cases"], dict):
                    # æ—§æ ¼å¼ï¼Œåˆ†ç±»æµ‹è¯•ç”¨ä¾‹
                    for category, cases in golden_cases["test_cases"].items():
                        if isinstance(cases, list):
                            result.extend(cases)
                elif isinstance(golden_cases["test_cases"], list):
                    # æ—§æ ¼å¼ï¼Œç›´æ¥åˆ—è¡¨
                    result = golden_cases["test_cases"]
        return result

    # å¹¶è¡Œæ‰§è¡ŒAIæµ‹è¯•ç”¨ä¾‹å’Œé»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹çš„æ ¼å¼åŒ–å¤„ç†
    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
        ai_future = executor.submit(extract_ai_testcases, ai_cases)
        golden_future = executor.submit(extract_golden_testcases, golden_cases)

        ai_testcases = ai_future.result()
        golden_testcases = golden_future.result()

    log(f"AIæµ‹è¯•ç”¨ä¾‹æ•°é‡: {len(ai_testcases)}, é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹æ•°é‡: {len(golden_testcases)}", important=True)

    # æ£€æŸ¥é‡å¤çš„æµ‹è¯•ç”¨ä¾‹
    ai_duplicate_info = find_duplicate_test_cases(ai_testcases)
    golden_duplicate_info = find_duplicate_test_cases(golden_testcases)

    log(f"AIæµ‹è¯•ç”¨ä¾‹é‡å¤ç‡: {ai_duplicate_info['duplicate_rate']}% ({ai_duplicate_info['duplicate_count']}ä¸ª)",
        important=True)
    log(f"é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹é‡å¤ç‡: {golden_duplicate_info['duplicate_rate']}% ({golden_duplicate_info['duplicate_count']}ä¸ª)",
        important=True)

    # è®°å½•é‡å¤ç±»å‹åˆ†å¸ƒ
    log(f"AIæµ‹è¯•ç”¨ä¾‹é‡å¤ç±»å‹åˆ†å¸ƒ: {json.dumps(ai_duplicate_info['duplicate_types'], ensure_ascii=False)}",
        important=True)
    if ai_duplicate_info['duplicate_categories']:
        log(f"AIæµ‹è¯•ç”¨ä¾‹æŒ‰ç±»åˆ«é‡å¤ç‡: {json.dumps(ai_duplicate_info['duplicate_categories'], ensure_ascii=False)}",
            important=True)

    # æå–åˆå¹¶å»ºè®®
    merge_suggestions_count = len(ai_duplicate_info.get("merge_suggestions", []))
    log(f"ç”Ÿæˆäº† {merge_suggestions_count} æ¡AIæµ‹è¯•ç”¨ä¾‹åˆå¹¶å»ºè®®", important=True)

    # æ„å»ºè¯„æµ‹æç¤º
    duplicate_info_text = f"""
# æµ‹è¯•ç”¨ä¾‹é‡å¤æƒ…å†µ
## AIæµ‹è¯•ç”¨ä¾‹é‡å¤æƒ…å†µ
- é‡å¤ç‡: {ai_duplicate_info['duplicate_rate']}%
- é‡å¤æµ‹è¯•ç”¨ä¾‹æ•°é‡: {ai_duplicate_info['duplicate_count']}ä¸ª
- æ ‡é¢˜é‡å¤çš„æµ‹è¯•ç”¨ä¾‹æ•°é‡: {len(ai_duplicate_info['title_duplicates'])}ä¸ª
- æ­¥éª¤é«˜åº¦ç›¸ä¼¼çš„æµ‹è¯•ç”¨ä¾‹æ•°é‡: {len(ai_duplicate_info['steps_duplicates'])}ä¸ª
- åˆå¹¶å»ºè®®æ•°é‡: {merge_suggestions_count}ä¸ª

## é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹é‡å¤æƒ…å†µ
- é‡å¤ç‡: {golden_duplicate_info['duplicate_rate']}%
- é‡å¤æµ‹è¯•ç”¨ä¾‹æ•°é‡: {golden_duplicate_info['duplicate_count']}ä¸ª
- æ ‡é¢˜é‡å¤çš„æµ‹è¯•ç”¨ä¾‹æ•°é‡: {len(golden_duplicate_info['title_duplicates'])}ä¸ª
- æ­¥éª¤é«˜åº¦ç›¸ä¼¼çš„æµ‹è¯•ç”¨ä¾‹æ•°é‡: {len(golden_duplicate_info['steps_duplicates'])}ä¸ª

å¦‚æœAIæµ‹è¯•ç”¨ä¾‹çš„é‡å¤ç‡æ˜æ˜¾é«˜äºé»„é‡‘æ ‡å‡†ï¼Œè¯·åœ¨æ”¹è¿›å»ºè®®ä¸­æå‡ºå‡å°‘é‡å¤æµ‹è¯•ç”¨ä¾‹çš„å»ºè®®ã€‚
"""

    # å¦‚æœæœ‰åˆå¹¶å»ºè®®ï¼Œæ·»åŠ åˆ°æç¤ºä¸­
    if merge_suggestions_count > 0:
        duplicate_info_text += "\n## AIæµ‹è¯•ç”¨ä¾‹åˆå¹¶å»ºè®®\n"
        for i, suggestion in enumerate(ai_duplicate_info.get("merge_suggestions", [])):
            suggestion_type = "æ ‡é¢˜é‡å¤" if suggestion["type"] == "title_duplicate" else "æ­¥éª¤ç›¸ä¼¼"
            case_ids = ", ".join(suggestion["case_ids"][:3])
            if len(suggestion["case_ids"]) > 3:
                case_ids += f" ç­‰{len(suggestion['case_ids'])}ä¸ªç”¨ä¾‹"

            merged_case = suggestion["merged_case"]
            duplicate_info_text += f"\n### åˆå¹¶å»ºè®® {i + 1}ï¼ˆ{suggestion_type}ï¼‰\n"
            duplicate_info_text += f"- æ¶‰åŠç”¨ä¾‹: {case_ids}\n"
            duplicate_info_text += f"- åˆå¹¶åæ ‡é¢˜: {merged_case['title']}\n"

            # æ·»åŠ æ­¥éª¤å’Œé¢„æœŸç»“æœæ‘˜è¦
            steps = merged_case.get("steps", "")
            if isinstance(steps, list) and len(steps) > 0:
                steps_preview = steps[0]
                if len(steps) > 1:
                    steps_preview += f" ... ç­‰{len(steps)}ä¸ªæ­¥éª¤"
                duplicate_info_text += f"- åˆå¹¶åæ­¥éª¤: {steps_preview}\n"

            expected = merged_case.get("expected_results", "")
            if isinstance(expected, list) and len(expected) > 0:
                expected_preview = expected[0]
                if len(expected) > 1:
                    expected_preview += f" ... ç­‰{len(expected)}ä¸ªé¢„æœŸç»“æœ"
                duplicate_info_text += f"- åˆå¹¶åé¢„æœŸç»“æœ: {expected_preview}\n"

    # æ„å»ºå®Œæ•´æç¤º
    prompt = f"""
# ä»»åŠ¡
è¯„ä¼°AIç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹ä¸é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹çš„è´¨é‡å¯¹æ¯”ã€‚

# è¯„ä¼°ç»´åº¦å’Œæƒé‡
1. **åŠŸèƒ½è¦†ç›–åº¦**ï¼ˆæƒé‡30%ï¼‰ï¼šè¯„ä¼°éœ€æ±‚è¦†ç›–ç‡ã€è¾¹ç•Œå€¼è¦†ç›–åº¦ã€åˆ†æ”¯è·¯å¾„è¦†ç›–ç‡
2. **ç¼ºé™·å‘ç°èƒ½åŠ›**ï¼ˆæƒé‡25%ï¼‰ï¼šè¯„ä¼°ç¼ºé™·æ£€æµ‹ç‡ã€çªå˜åˆ†æ•°ã€å¤±è´¥ç”¨ä¾‹æ¯”ä¾‹
3. **å·¥ç¨‹æ•ˆç‡**ï¼ˆæƒé‡20%ï¼‰ï¼šè¯„ä¼°æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆé€Ÿåº¦ã€ç»´æŠ¤æˆæœ¬ã€CI/CDé›†æˆåº¦
4. **è¯­ä¹‰è´¨é‡**ï¼ˆæƒé‡15%ï¼‰ï¼šè¯„ä¼°è¯­ä¹‰å‡†ç¡®æ€§ã€äººå·¥å¯è¯»æ€§ã€æ–­è¨€æè¿°æ¸…æ™°åº¦
5. **å®‰å…¨ä¸ç»æµæ€§**ï¼ˆæƒé‡10%ï¼‰ï¼šè¯„ä¼°æ¶æ„ä»£ç ç‡ã€å†—ä½™ç”¨ä¾‹æ¯”ä¾‹ã€ç»¼åˆæˆæœ¬

{duplicate_info_text}

# è¯„åˆ†å…¬å¼
æ€»åˆ† = 0.3Ã—åŠŸèƒ½è¦†ç›–å¾—åˆ† + 0.25Ã—ç¼ºé™·å‘ç°å¾—åˆ† + 0.2Ã—å·¥ç¨‹æ•ˆç‡å¾—åˆ† + 0.15Ã—è¯­ä¹‰è´¨é‡å¾—åˆ† + 0.1Ã—å®‰å…¨ç»æµå¾—åˆ†
å„ç»´åº¦å¾—åˆ† = (AIæŒ‡æ ‡å€¼/äººå·¥åŸºå‡†å€¼)Ã—10ï¼ˆæ»¡åˆ†10åˆ†ï¼‰

# AIç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹
```json
{json.dumps(ai_testcases, ensure_ascii=False, indent=2)}
```

# é»„é‡‘æ ‡å‡†æµ‹è¯•ç”¨ä¾‹
```json
{json.dumps(golden_testcases, ensure_ascii=False, indent=2)}
```

# è¾“å‡ºè¦æ±‚
å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºè¯„ä¼°ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–å†…å®¹ï¼Œä¸è¦ä½¿ç”¨```jsonæˆ–å…¶ä»–ä»£ç å—åŒ…è£…ï¼Œä¸è¦è¿”å›Markdownæ ¼å¼å†…å®¹ã€‚ç›´æ¥è¾“å‡ºä¸‹é¢è¿™ç§JSONç»“æ„ï¼š

```json
{{
  "evaluation_summary": {{
    "overall_score": "åˆ†æ•°ï¼ˆ1-5ä¹‹é—´çš„ä¸€ä½å°æ•°ï¼‰",
    "final_suggestion": "å¦‚ä½•æ”¹è¿›æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆçš„å»ºè®®ï¼Œå¦‚æœ‰è¾ƒé«˜çš„é‡å¤ç‡ï¼Œè¯·æå‡ºé™ä½é‡å¤çš„å»ºè®®ï¼Œå¹¶å‚è€ƒæˆ‘æä¾›çš„å…·ä½“åˆå¹¶å»ºè®®"
  }},
  "detailed_report": {{
    "format_compliance": {{
      "score": "æ ¼å¼åˆè§„æ€§å¾—åˆ†ï¼ˆ1-5ä¹‹é—´çš„ä¸€ä½å°æ•°ï¼‰",
      "reason": "å¾—åˆ†ç†ç”±"
    }},
    "content_accuracy": {{
      "score": "å†…å®¹å‡†ç¡®æ€§å¾—åˆ†ï¼ˆ1-5ä¹‹é—´çš„ä¸€ä½å°æ•°ï¼‰",
      "reason": "å¾—åˆ†ç†ç”±"
    }},
    "test_coverage": {{
      "score": "æµ‹è¯•è¦†ç›–åº¦å¾—åˆ†ï¼ˆ1-5ä¹‹é—´çš„ä¸€ä½å°æ•°ï¼‰",
      "reason": "å¾—åˆ†ç†ç”±",
      "analysis": {{
        "covered_features": [
          "å·²è¦†ç›–åŠŸèƒ½1",
          "å·²è¦†ç›–åŠŸèƒ½2"
        ],
        "missed_features_or_scenarios": [
          "æœªè¦†ç›–åŠŸèƒ½/åœºæ™¯1",
          "æœªè¦†ç›–åŠŸèƒ½/åœºæ™¯2"
        ],
        "scenario_types_found": [
          "å‘ç°çš„åœºæ™¯ç±»å‹ï¼Œå¦‚æ­£é¢ç”¨ä¾‹ã€è´Ÿé¢ç”¨ä¾‹ã€è¾¹ç•Œç”¨ä¾‹ç­‰"
        ]
      }}
    }},
    "functional_coverage": {{
      "score": "åŠŸèƒ½è¦†ç›–åº¦å¾—åˆ†ï¼ˆ1-5ä¹‹é—´çš„ä¸€ä½å°æ•°ï¼‰",
      "reason": "å¾—åˆ†ç†ç”±"
    }},
    "defect_detection": {{
      "score": "ç¼ºé™·å‘ç°èƒ½åŠ›å¾—åˆ†ï¼ˆ1-5ä¹‹é—´çš„ä¸€ä½å°æ•°ï¼‰",
      "reason": "å¾—åˆ†ç†ç”±"
    }},
    "engineering_efficiency": {{
      "score": "å·¥ç¨‹æ•ˆç‡å¾—åˆ†ï¼ˆ1-5ä¹‹é—´çš„ä¸€ä½å°æ•°ï¼‰",
      "reason": "å¾—åˆ†ç†ç”±ï¼Œå¦‚æœ‰è¾ƒé«˜çš„é‡å¤ç‡ï¼Œè¯·åœ¨æ­¤å¤„æåŠ"
    }},
    "semantic_quality": {{
      "score": "è¯­ä¹‰è´¨é‡å¾—åˆ†ï¼ˆ1-5ä¹‹é—´çš„ä¸€ä½å°æ•°ï¼‰",
      "reason": "å¾—åˆ†ç†ç”±"
    }},
    "security_economy": {{
      "score": "å®‰å…¨ä¸ç»æµæ€§å¾—åˆ†ï¼ˆ1-5ä¹‹é—´çš„ä¸€ä½å°æ•°ï¼‰",
      "reason": "å¾—åˆ†ç†ç”±ï¼Œå¦‚æœ‰è¾ƒé«˜çš„é‡å¤ç‡ï¼Œè¯·åœ¨æ­¤å¤„æåŠå†—ä½™ç‡"
    }},
    "duplicate_analysis": {{
      "score": "æµ‹è¯•ç”¨ä¾‹é‡å¤åˆ†æå¾—åˆ†ï¼ˆ1-5ä¹‹é—´çš„ä¸€ä½å°æ•°ï¼‰",
      "reason": "åˆ†æé‡å¤æµ‹è¯•ç”¨ä¾‹çš„å½±å“",
      "merge_suggestions": "å…·ä½“å¦‚ä½•åˆå¹¶é‡å¤æµ‹è¯•ç”¨ä¾‹çš„å»ºè®®ï¼Œå¯ä»¥å‚è€ƒæˆ‘æä¾›çš„åˆå¹¶å»ºè®®"
    }}
  }},
  "duplicate_types": {{
    "title": {ai_duplicate_info['duplicate_types'].get('title', 0)},
    "steps": {ai_duplicate_info['duplicate_types'].get('steps', 0)},
    "expected_results": {ai_duplicate_info['duplicate_types'].get('expected_results', 0)},
    "mixed": {ai_duplicate_info['duplicate_types'].get('mixed', 0)}
  }},
  "duplicate_categories": {json.dumps(ai_duplicate_info.get('duplicate_categories', {}))}
}}
```
"""

    system_prompt = "ä½ æ˜¯ä¸€ä½ç²¾é€šè½¯ä»¶æµ‹è¯•å’ŒæŠ€æœ¯æ–‡æ¡£å†™ä½œçš„ä¸“å®¶ã€‚è¯·æ ¹æ®è¯„ä¼°ç»“æœç”Ÿæˆä¸€ä»½ä¸“ä¸šã€æ¸…æ™°çš„Markdownæ ¼å¼æŠ¥å‘Šï¼Œå¹¶ä½¿ç”¨Mermaidå›¾è¡¨å¯è§†åŒ–å…³é”®æ•°æ®ã€‚è¯·ç›´æ¥ä¿ç•™å¹¶ä½¿ç”¨æˆ‘æä¾›çš„è¯„åˆ†è¡¨æ ¼æ ¼å¼ï¼Œä¸è¦ä¿®æ”¹å…¶ç»“æ„ã€‚è¯·ç›´æ¥è¾“å‡ºMarkdownæ ¼å¼ï¼Œä¸è¦å°è¯•è¾“å‡ºJSONã€‚ä¸¥æ ¼ç¦æ­¢åœ¨æ–‡æ¡£å¼€å¤´æ·»åŠ 'markdown'è¿™ä¸ªè¯ï¼Œç›´æ¥ä»¥'# 'å¼€å¤´çš„æ ‡é¢˜å¼€å§‹ã€‚ä¸è¦åœ¨å†…å®¹å¤–åŒ…å«```æˆ–```markdownæ ‡è®°ï¼Œå®Œå…¨é¿å…ä½¿ç”¨ä»£ç å—ï¼Œä½†ä¿ç•™æä¾›çš„Mermaidå›¾è¡¨è¯­æ³•ã€‚"

    # ä½¿ç”¨è¾ƒä½çš„temperatureå€¼ï¼Œç¡®ä¿è¯„æµ‹ç»“æœçš„ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§
    result = await async_call_llm(
        session,
        prompt,
        system_prompt,
        temperature=LLM_TEMPERATURE  # ä½¿ç”¨é…ç½®ä¸­çš„ä½temperatureå€¼
    )

    if not result:
        log("æµ‹è¯•ç”¨ä¾‹è¯„æµ‹å¤±è´¥", important=True)
        return None

    log("æµ‹è¯•ç”¨ä¾‹è¯„æµ‹å®Œæˆ", important=True)
    return result


# æ·»åŠ æµ‹è¯•è¦†ç›–æµç¨‹å›¾ç”Ÿæˆå‡½æ•°
def generate_test_coverage_flow_chart(test_cases):
    """
    æ ¹æ®æµ‹è¯•ç”¨ä¾‹å†…å®¹åŠ¨æ€ç”Ÿæˆæµ‹è¯•è¦†ç›–æµç¨‹å›¾

    :param test_cases: æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
    :return: Mermaidæ ¼å¼çš„æµç¨‹å›¾
    """
    # æå–æµ‹è¯•ç”¨ä¾‹IDä¸­çš„åŠŸèƒ½æ¨¡å—ä¿¡æ¯
    modules = {}
    submodules = {}

    for case in test_cases:
        case_id = case.get("case_id", "")
        title = case.get("title", "")

        # æå–ä¸»è¦åŠŸèƒ½æ¨¡å—å’Œå­åŠŸèƒ½æ¨¡å—
        parts = case_id.split('-')
        if len(parts) >= 2:
            main_module = parts[0]
            if len(parts) >= 3:
                sub_module = parts[1]

                # è®°å½•æ¨¡å—
                if main_module not in modules:
                    modules[main_module] = 0
                modules[main_module] += 1

                # è®°å½•å­æ¨¡å—
                module_key = f"{main_module}-{sub_module}"
                if module_key not in submodules:
                    submodules[module_key] = {
                        "name": sub_module,
                        "parent": main_module,
                        "count": 0
                    }
                submodules[module_key]["count"] += 1

    # æå–ä¸»è¦åŠŸèƒ½å’Œå­åŠŸèƒ½çš„å…³ç³»
    # å¦‚æœæµ‹è¯•ç”¨ä¾‹æ ‡é¢˜ä¸­åŒ…å«ç±»ä¼¼"xxæµç¨‹"ã€"xxåŠŸèƒ½"ã€"xxéªŒè¯"ç­‰è¯è¯­ï¼Œæå–ä¸ºåŠŸèƒ½ç‚¹
    features = {}
    for case in test_cases:
        title = case.get("title", "")
        if not title:
            continue

        # å°è¯•æå–åŠŸèƒ½ç‚¹
        feature = None
        if "æµç¨‹" in title:
            feature = title.split("æµç¨‹")[0] + "æµç¨‹"
        elif "åŠŸèƒ½" in title:
            feature = title.split("åŠŸèƒ½")[0] + "åŠŸèƒ½"
        elif "éªŒè¯" in title:
            feature = title.split("éªŒè¯")[0] + "éªŒè¯"
        elif "-" in title:
            feature = title.split("-")[0]
        elif "ï¼š" in title or ":" in title:
            feature = title.split("ï¼š")[0].split(":")[0]
        else:
            # å¦‚æœæ²¡æœ‰ç‰¹å®šæ ‡è¯†ï¼Œä½¿ç”¨å‰ä¸‰ä¸ªè¯ä½œä¸ºåŠŸèƒ½ç‚¹
            words = title.split()
            if words:
                feature = words[0]
                if len(words) > 1:
                    feature += words[1]

        if feature and len(feature) <= 20:  # é™åˆ¶åŠŸèƒ½ç‚¹åç§°é•¿åº¦
            if feature not in features:
                features[feature] = {
                    "count": 0,
                    "subfeatures": set()
                }
            features[feature]["count"] += 1

            # å°è¯•æå–å­åŠŸèƒ½ç‚¹
            steps = case.get("steps", [])
            for step in steps:
                if isinstance(step, str) and step:
                    # æå–æ­¥éª¤ä¸­çš„å…³é”®åŠ¨ä½œ
                    words = step.split("ã€‚")[0].split()
                    action = ""
                    for word in words:
                        if "ç‚¹å‡»" in word or "è¾“å…¥" in word or "é€‰æ‹©" in word or "éªŒè¯" in word:
                            action = word
                            break

                    # å°†ifè¯­å¥ç§»åˆ°forå¾ªç¯å¤–éƒ¨ï¼Œä¿®å¤ç¼©è¿›
                    if action and len(action) <= 15:
                        features[feature]["subfeatures"].add(action)

    # æŒ‰æµ‹è¯•ç”¨ä¾‹æ•°é‡æ’åºåŠŸèƒ½ç‚¹
    sorted_features = sorted(features.items(), key=lambda x: x[1]["count"], reverse=True)

    # ç”ŸæˆMermaidå›¾è¡¨
    chart = "```mermaid\ngraph TD\n"

    # æ·»åŠ ä¸»èŠ‚ç‚¹
    chart += "    A[æµ‹è¯•è¦†ç›–èŒƒå›´] --> B[åŠŸèƒ½éªŒè¯]\n"
    chart += "    A --> C[å¼‚å¸¸å¤„ç†]\n"
    chart += "    A --> D[è¾¹ç•Œæµ‹è¯•]\n"

    # æ·»åŠ ä¸»è¦åŠŸèƒ½ç‚¹ï¼ˆæœ€å¤š8ä¸ªï¼Œé¿å…å›¾è¡¨è¿‡å¤§ï¼‰
    node_id = 0
    node_map = {}
    edge_set = set()  # é¿å…é‡å¤çš„è¾¹

    for i, (feature, info) in enumerate(sorted_features[:8]):
        if i >= 8:
            break

        node_id += 1
        feature_node = f"F{node_id}"
        node_map[feature] = feature_node

        # æ·»åŠ åŠŸèƒ½ç‚¹èŠ‚ç‚¹
        chart += f"    B --> {feature_node}[{feature}]\n"

        # æ·»åŠ å­åŠŸèƒ½ç‚¹ï¼ˆæ¯ä¸ªåŠŸèƒ½ç‚¹æœ€å¤šæ·»åŠ 5ä¸ªå­åŠŸèƒ½ï¼‰
        subfeatures = list(info["subfeatures"])[:5]
        for j, subfeature in enumerate(subfeatures):
            if j >= 5:
                break

            node_id += 1
            subfeature_node = f"SF{node_id}"

            # åˆ›å»ºè¾¹çš„æ ‡è¯†
            edge = f"{feature_node}->{subfeature_node}"

            # é¿å…æ·»åŠ é‡å¤çš„è¾¹
            if edge not in edge_set:
                chart += f"    {feature_node} --> {subfeature_node}[{subfeature}]\n"
                edge_set.add(edge)

    # æ·»åŠ å¼‚å¸¸å¤„ç†ç¤ºä¾‹èŠ‚ç‚¹
    chart += "    C --> E1[è¾“å…¥éªŒè¯]\n"
    chart += "    C --> E2[è¶…æ—¶å¤„ç†]\n"
    chart += "    C --> E3[å®‰å…¨æ£€æŸ¥]\n"

    # æ·»åŠ è¾¹ç•Œæµ‹è¯•ç¤ºä¾‹èŠ‚ç‚¹
    chart += "    D --> B1[æœ€å¤§å€¼æµ‹è¯•]\n"
    chart += "    D --> B2[æœ€å°å€¼æµ‹è¯•]\n"

    chart += "```\n"
    return chart


async def generate_markdown_report(session: aiohttp.ClientSession, evaluation_result):
    """
    ç”ŸæˆMarkdownæ ¼å¼çš„è¯„æµ‹æŠ¥å‘Š

    :param session: aiohttpä¼šè¯
    :param evaluation_result: è¯„æµ‹ç»“æœ
    :return: Markdownæ ¼å¼çš„æŠ¥å‘Š
    """
    log("å¼€å§‹ç”ŸæˆMarkdownæŠ¥å‘Š", important=True)

    # ç¡®ä¿æ—¥å¿—è®°å½•æŒ‰ç…§æ­£ç¡®çš„é¡ºåºæ‰§è¡Œ
    await asyncio.sleep(0.1)  # æ·»åŠ å°å»¶è¿Ÿï¼Œç¡®ä¿æ—¥å¿—é¡ºåº

    # ä»è¯„ä¼°ç»“æœä¸­æå–å…³é”®æ•°æ®ç”¨äºå¯è§†åŒ–
    mermaid_data = {
        "scores": {},
        "duplicate_rates": {
            "ai": 0,
            "golden": 0
        },
        "duplicate_types": {},
        "coverage": []
    }

    # å°è¯•ä»è¯„ä¼°ç»“æœè·å–æµ‹è¯•ç”¨ä¾‹æ•°æ®
    ai_testcases = []
    if isinstance(evaluation_result, dict):
        # å°è¯•ä»ä¸åŒå¯èƒ½çš„å­—æ®µä¸­æå–æµ‹è¯•ç”¨ä¾‹
        if "test_cases" in evaluation_result:
            ai_testcases = evaluation_result.get("test_cases", [])
        elif "detailed_report" in evaluation_result and "test_coverage" in evaluation_result["detailed_report"]:
            if "analysis" in evaluation_result["detailed_report"]["test_coverage"]:
                coverage_analysis = evaluation_result["detailed_report"]["test_coverage"]["analysis"]
                # å°è¯•ä»è¦†ç›–åˆ†æä¸­æå–åŸºæœ¬ä¿¡æ¯ç”¨äºç”Ÿæˆæµç¨‹å›¾
                if "covered_features" in coverage_analysis:
                    covered_features = coverage_analysis["covered_features"]
                    # å°†è¦†ç›–çš„åŠŸèƒ½ç‚¹è½¬æ¢ä¸ºç®€å•çš„æµ‹è¯•ç”¨ä¾‹ç»“æ„
                    ai_testcases = [{"case_id": f"FEAT-{i + 1}", "title": feature}
                                    for i, feature in enumerate(covered_features)]

    # åŠ¨æ€ç”Ÿæˆæµ‹è¯•è¦†ç›–æµç¨‹å›¾
    coverage_chart = generate_test_coverage_flow_chart(ai_testcases)

    # æå–å„ç»´åº¦è¯„åˆ†
    if isinstance(evaluation_result, dict) and "detailed_report" in evaluation_result:
        detailed = evaluation_result["detailed_report"]

        # æå–è¯„åˆ†æ•°æ®
        for key, value in detailed.items():
            if isinstance(value, dict) and "score" in value:
                score_key = key.replace("_", " ").title()
                try:
                    score_value = float(value["score"])
                    mermaid_data["scores"][score_key] = score_value
                except (ValueError, TypeError):
                    mermaid_data["scores"][score_key] = value["score"]

    # è·å–æ•´ä½“è¯„åˆ†
    overall_score = "N/A"
    if isinstance(evaluation_result, dict) and "evaluation_summary" in evaluation_result:
        overall_score = evaluation_result["evaluation_summary"].get("overall_score", "N/A")
        mermaid_data["scores"]["Overall Score"] = overall_score

    # ç”Ÿæˆè¯„åˆ†é›·è¾¾å›¾
    # ç”±äºMermaidä¸æ”¯æŒçœŸæ­£çš„é›·è¾¾å›¾ï¼Œæ”¹ç”¨Markdownè¡¨æ ¼å’Œè¯„åˆ†è¡¨ç¤º
    radar_chart = f"## ğŸ“Š ç»¼åˆè¯„åˆ† (æ€»ä½“: {overall_score}/5.0)\n\n"
    radar_chart += "| è¯„ä¼°ç»´åº¦ | å¾—åˆ† | è¯„åˆ†å¯è§†åŒ– |\n"
    radar_chart += "|---------|------|------------|\n"

    # è·å–ç»´åº¦æ•°æ®
    dimension_scores = []
    for name, score in mermaid_data["scores"].items():
        if name != "Overall Score":  # æ’é™¤æ€»ä½“è¯„åˆ†
            try:
                # ç¡®ä¿åˆ†æ•°æ˜¯æ•°å€¼
                score_value = float(score) if isinstance(score, str) else score
                # å°†è‹±æ–‡ç»´åº¦åç§°è½¬ä¸ºä¸­æ–‡
                chinese_name = name
                if name == "Format Compliance":
                    chinese_name = "æ ¼å¼åˆè§„æ€§"
                elif name == "Content Accuracy":
                    chinese_name = "å†…å®¹å‡†ç¡®æ€§"
                elif name == "Test Coverage":
                    chinese_name = "æµ‹è¯•è¦†ç›–åº¦"
                elif name == "Functional Coverage":
                    chinese_name = "åŠŸèƒ½è¦†ç›–åº¦"
                elif name == "Defect Detection":
                    chinese_name = "ç¼ºé™·å‘ç°èƒ½åŠ›"
                elif name == "Engineering Efficiency":
                    chinese_name = "å·¥ç¨‹æ•ˆç‡"
                elif name == "Semantic Quality":
                    chinese_name = "è¯­ä¹‰è´¨é‡"
                elif name == "Security Economy":
                    chinese_name = "å®‰å…¨ä¸ç»æµæ€§"
                elif name == "Duplicate Analysis":
                    chinese_name = "é‡å¤æ€§åˆ†æ"
                dimension_scores.append((chinese_name, score_value))
            except (ValueError, TypeError):
                # å¦‚æœæ— æ³•è½¬æ¢ä¸ºæ•°å€¼ï¼Œè·³è¿‡
                continue

    # æŒ‰è¯„åˆ†ä»é«˜åˆ°ä½æ’åº
    dimension_scores.sort(key=lambda x: x[1], reverse=True)

    # æ·»åŠ æ•°æ®è¡Œ
    if dimension_scores:
        for name, score in dimension_scores:
            # ç”Ÿæˆè¯„åˆ†å¯è§†åŒ–
            score_int = int(score)
            stars = "â˜…" * score_int + "â˜†" * (5 - score_int)
            radar_chart += f"| {name} | {score} | {stars} |\n"

    radar_chart += "\n"

    # æ·»åŠ ä¸“é—¨çš„è¯„åˆ†å›¾
    radar_chart += "```mermaid\npie\n    title å„ç»´åº¦è¯„åˆ†åˆ†å¸ƒ\n"
    for name, score in dimension_scores:
        short_name = name.replace("Coverage", "è¦†ç›–").replace("Analysis", "åˆ†æ")
        radar_chart += f"    \"{short_name}\" : {score}\n"
    radar_chart += "```\n\n"

    # æå–é‡å¤ç‡å’Œé‡å¤ç±»å‹æ•°æ®
    ai_duplicate_rate = 0
    golden_duplicate_rate = 0
    duplicate_types = {}

    # å°è¯•ä»è¯„ä¼°ç»“æœä¸­æ‰¾åˆ°é‡å¤ç‡æ•°æ®
    if "duplicate_types" in evaluation_result:
        duplicate_types = evaluation_result.get("duplicate_types", {})

        # ä»evaluation_resultç›´æ¥è·å–é‡å¤ç‡æ•°æ®
        try:
            # å°è¯•ä»å…·ä½“æ•°æ®ä¸­æå–é‡å¤ç‡
            duplicate_info = evaluation_result.get("duplicate_info", {})
            if duplicate_info:
                ai_duplicate_rate = duplicate_info.get("ai_duplicate_rate", 0)
                golden_duplicate_rate = duplicate_info.get("golden_duplicate_rate", 0)
                mermaid_data["duplicate_rates"]["ai"] = float(ai_duplicate_rate)
                mermaid_data["duplicate_rates"]["golden"] = float(golden_duplicate_rate)
        except:
            # å¦‚æœæå–å¤±è´¥ï¼Œä¿ç•™åˆå§‹åŒ–å€¼
            pass
    else:
        # å°è¯•ä»åŸå› æè¿°ä¸­æå–æ•°æ®
        if "duplicate_analysis" in evaluation_result.get("detailed_report", {}):
            dup_analysis = evaluation_result["detailed_report"]["duplicate_analysis"]
            if "reason" in dup_analysis:
                # å°è¯•ä»åŸå› æè¿°ä¸­æå–æ•°å­—
                ai_rates = re.findall(r"AI[^0-9]*([0-9.]+)%", dup_analysis["reason"])
                golden_rates = re.findall(r"é»„é‡‘[^0-9]*([0-9.]+)%", dup_analysis["reason"])

                if ai_rates:
                    mermaid_data["duplicate_rates"]["ai"] = float(ai_rates[0])
                    ai_duplicate_rate = float(ai_rates[0])
                if golden_rates:
                    mermaid_data["duplicate_rates"]["golden"] = float(golden_rates[0])
                    golden_duplicate_rate = float(golden_rates[0])

    # å°è¯•ä»è¯„ä¼°ç»“æœä¸­æå–é‡å¤ç±»å‹æ•°æ®
    dup_types = {"æ ‡é¢˜é‡å¤": 0, "æ­¥éª¤é‡å¤": 0, "é¢„æœŸç»“æœé‡å¤": 0, "æ··åˆé‡å¤": 0}

    # å¦‚æœevaluation_resultä¸­æœ‰å…·ä½“çš„duplicate_typesæ•°æ®ï¼Œåˆ™ä½¿ç”¨å®ƒ
    if "duplicate_types" in evaluation_result:
        try:
            duplicate_types = evaluation_result.get("duplicate_types", {})
            if duplicate_types and sum(duplicate_types.values()) > 0:
                dup_types = {
                    "æ ‡é¢˜é‡å¤": duplicate_types.get("title", 0),
                    "æ­¥éª¤é‡å¤": duplicate_types.get("steps", 0),
                    "é¢„æœŸç»“æœé‡å¤": duplicate_types.get("expected_results", 0),
                    "æ··åˆé‡å¤": duplicate_types.get("mixed", 0)
                }
                # ä¿å­˜åˆ°mermaid_data
                mermaid_data["duplicate_types"] = dup_types
        except:
            pass
    else:
        # å°è¯•ä»åŸå› æè¿°ä¸­æå–é‡å¤ç±»å‹åˆ†å¸ƒ
        if "duplicate_analysis" in evaluation_result.get("detailed_report", {}):
            reason = evaluation_result["detailed_report"]["duplicate_analysis"].get("reason", "")

            # å°è¯•ä»reasonä¸­æå–æ•°æ®
            title_dup = re.findall(r"æ ‡é¢˜é‡å¤[^0-9]*([0-9]+)ä¸ª", reason)
            steps_dup = re.findall(r"æ­¥éª¤[ç›¸ä¼¼|é‡å¤][^0-9]*([0-9]+)ä¸ª", reason)

            if title_dup:
                dup_types["æ ‡é¢˜é‡å¤"] = int(title_dup[0])
            if steps_dup:
                dup_types["æ­¥éª¤é‡å¤"] = int(steps_dup[0])

            # ä¿å­˜åˆ°mermaid_data
            mermaid_data["duplicate_types"] = dup_types

    # åˆå¹¶ç”Ÿæˆé‡å¤æµ‹è¯•ç”¨ä¾‹åˆ†æå›¾
    duplicate_combined_chart = "## ğŸ”„ é‡å¤æµ‹è¯•ç”¨ä¾‹åˆ†æ\n\n"

    # ä½¿ç”¨æ–‡å­—æè¿°æ›¿ä»£å›¾è¡¨
    duplicate_combined_chart += "> ### é‡å¤æƒ…å†µç»Ÿè®¡æ‘˜è¦\n>\n"

    # æ·»åŠ é‡å¤ç‡æ•°æ®
    duplicate_combined_chart += f"> **AIæµ‹è¯•ç”¨ä¾‹é‡å¤ç‡**: {ai_duplicate_rate}%\n>\n"
    duplicate_combined_chart += f"> **é»„é‡‘æ ‡å‡†é‡å¤ç‡**: {golden_duplicate_rate}%\n>\n"

    # æ·»åŠ é‡å¤ç±»å‹æ•°æ®
    duplicate_combined_chart += "> **é‡å¤ç±»å‹æ˜ç»†**:\n"
    has_duplicates = False
    for dup_type, count in dup_types.items():
        if count > 0:
            has_duplicates = True
            duplicate_combined_chart += f"> - {dup_type}: **{count}ä¸ª**\n"

    # å¦‚æœæ‰€æœ‰æ•°æ®éƒ½æ˜¯0ï¼Œæ·»åŠ æ— é‡å¤è¯´æ˜
    if not has_duplicates:
        duplicate_combined_chart += "> - æœªå‘ç°é‡å¤æµ‹è¯•ç”¨ä¾‹\n"

    # æ·»åŠ æ¨¡å—åˆ†å¸ƒçš„æ–‡å­—æè¿°
    if "duplicate_categories" in evaluation_result:
        duplicate_categories = evaluation_result.get("duplicate_categories", {})
        if duplicate_categories:
            duplicate_combined_chart += ">\n> **é‡å¤ç”¨ä¾‹æ¨¡å—åˆ†å¸ƒ**:\n"
            for category, value in duplicate_categories.items():
                # æ£€æŸ¥valueæ˜¯å¦ä¸ºå­—å…¸ï¼ˆanalyzer.pyä¸­çš„ç»“æ„ï¼‰æˆ–æ•´æ•°
                if isinstance(value, dict) and "total" in value:
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œæå–duplicate_rateæˆ–è®¡ç®—é‡å¤ç‡
                    duplicate_count = value.get("title_duplicates", 0) + value.get("steps_duplicates", 0)
                    if duplicate_count > 0:
                        duplicate_combined_chart += f"> - {category}: **{duplicate_count}ä¸ª**\n"
                elif isinstance(value, (int, float)) and value > 0:
                    # å¦‚æœæ˜¯æ•°å­—ä¸”å¤§äº0
                    duplicate_combined_chart += f"> - {category}: **{value}ä¸ª**\n"
                # å¿½ç•¥å…¶ä»–ç±»å‹æˆ–é›¶å€¼

    duplicate_combined_chart += "\n\n"

    # ç”Ÿæˆåˆå¹¶å»ºè®®æ–¹æ¡ˆå›¾
    merge_suggestions = []
    if isinstance(evaluation_result, dict) and "detailed_report" in evaluation_result:
        detailed = evaluation_result["detailed_report"]
        if "duplicate_analysis" in detailed and "merge_suggestions" in detailed["duplicate_analysis"]:
            merge_suggestions = detailed["duplicate_analysis"]["merge_suggestions"]

    # ä»duplicate_infoä¸­è·å–åˆå¹¶å»ºè®®
    if "duplicate_info" in evaluation_result and "merge_suggestions" in evaluation_result["duplicate_info"]:
        merge_suggestions = evaluation_result["duplicate_info"]["merge_suggestions"]

    # å¦‚æœæœ‰åˆå¹¶å»ºè®®ï¼Œç”Ÿæˆå›¾è¡¨
    if merge_suggestions and isinstance(merge_suggestions, str) and len(merge_suggestions) > 10:
        # å¦‚æœmerge_suggestionsæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•æå–æœ‰ç”¨ä¿¡æ¯
        merge_chart = "### ğŸ› ï¸ åˆå¹¶å»ºè®®æ–¹æ¡ˆ\n\n"
        merge_chart += "> " + merge_suggestions.replace("\n", "\n> ") + "\n\n"
    elif merge_suggestions and (isinstance(merge_suggestions, list) and len(merge_suggestions) > 0):
        # å¦‚æœæœ‰ç»“æ„åŒ–çš„åˆå¹¶å»ºè®®ï¼Œç”Ÿæˆæµç¨‹å›¾
        merge_chart = "### ğŸ› ï¸ åˆå¹¶å»ºè®®æ–¹æ¡ˆ\n```mermaid\ngraph LR\n"
        merge_chart += "    A[é‡å¤ç”¨ä¾‹] --> B[åˆå¹¶æ–¹æ¡ˆ]\n"

        for i, suggestion in enumerate(merge_suggestions[:4]):  # é™åˆ¶æœ€å¤šæ˜¾ç¤º4ä¸ªå»ºè®®
            index = i + 1
            case_ids = ""
            title = ""

            if isinstance(suggestion, dict):
                # æå–æ¡ˆä¾‹ID
                if "case_ids" in suggestion:
                    if isinstance(suggestion["case_ids"], list):
                        case_ids = "/".join(suggestion["case_ids"][:2])
                        if len(suggestion["case_ids"]) > 2:
                            case_ids += "..."
                    else:
                        case_ids = str(suggestion["case_ids"])

                # æå–æ ‡é¢˜
                if "merged_case" in suggestion and "title" in suggestion["merged_case"]:
                    title = suggestion["merged_case"]["title"]
                elif "title" in suggestion:
                    title = suggestion["title"]
                else:
                    title = f"åˆå¹¶ç”¨ä¾‹ {index}"

            # é˜²æ­¢æ ‡é¢˜è¿‡é•¿
            if len(title) > 30:
                title = title[:27] + "..."

            # å»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œé¿å…Mermaidè¯­æ³•é”™è¯¯
            title = title.replace("(", "").replace(")", "").replace("[", "").replace("]", "")

            # æ·»åŠ åˆ°å›¾è¡¨ä¸­
            merge_chart += f"    Case{index}[\"ç”¨ä¾‹ç»„ {case_ids}\"] --> Merge{index}[\"{title}\"]\n"

        merge_chart += "```\n\n"
    else:
        # æ²¡æœ‰åˆå¹¶å»ºè®®æˆ–åˆå¹¶å»ºè®®æ ¼å¼ä¸é€‚åˆç”Ÿæˆå›¾è¡¨
        merge_chart = "### ğŸ› ï¸ åˆå¹¶å»ºè®®æ–¹æ¡ˆ\n\n"
        merge_chart += "> å½“å‰æµ‹è¯•ç”¨ä¾‹ä¸éœ€è¦åˆå¹¶æˆ–æ²¡æœ‰æä¾›åˆå¹¶å»ºè®®ä¿¡æ¯\n\n"

    # å°†åˆå¹¶å»ºè®®å›¾æ·»åŠ åˆ°é‡å¤åˆ†æåé¢
    duplicate_combined_chart += merge_chart

    # æ·»åŠ æ ‘çŠ¶è¯„ä¼°æ¡†æ¶å›¾æ¨¡æ¿
    evaluation_framework_chart = """## ğŸŒ³ æµ‹è¯•ç”¨ä¾‹è¯„ä¼°æ¡†æ¶
```mermaid
graph TD
    A[æµ‹è¯•ç”¨ä¾‹è¯„ä¼°] --> B[æ ¼å¼åˆè§„æ€§]
    A --> C[å†…å®¹è´¨é‡]
    A --> D[åŠŸèƒ½è¦†ç›–]
    A --> E[å·¥ç¨‹æ•ˆç‡]
    A --> F[å®‰å…¨æ€§]

    C --> C1[å†…å®¹å‡†ç¡®æ€§]
    C --> C2[è¯­ä¹‰è´¨é‡]

    D --> D1[æµ‹è¯•è¦†ç›–åº¦]
    D --> D2[åŠŸèƒ½è¦†ç›–åº¦]
    D --> D3[ç¼ºé™·å‘ç°èƒ½åŠ›]

    E --> E1[é‡å¤æ€§åˆ†æ]
    E --> E2[å·¥ç¨‹æ•ˆç‡]

    F --> F1[å®‰å…¨ä¸ç»æµæ€§]

    classDef important fill:#f9d77e,stroke:#f9a11b,stroke-width:2px;
    classDef quality fill:#a8d6ff,stroke:#4a86e8,stroke-width:2px;
    classDef coverage fill:#b6d7a8,stroke:#6aa84f,stroke-width:2px;

    class A,D important;
    class B,C,F quality;
    class D1,D2,D3 coverage;
```

"""

    # åœ¨æç¤ºä¸­è¯´æ˜ä½¿ç”¨æ›´æ–°çš„å›¾è¡¨è¯­æ³•
    prompt = f"""
# ä»»åŠ¡
åŸºäºæä¾›çš„æµ‹è¯•ç”¨ä¾‹è¯„ä¼°ç»“æœï¼Œç”Ÿæˆä¸€ä»½è¯¦ç»†çš„Markdownæ ¼å¼è¯„ä¼°æŠ¥å‘Šï¼ŒåŒ…å«Mermaidå›¾è¡¨å¯è§†åŒ–å…³é”®æ•°æ®ã€‚

# è¯„ä¼°ç»“æœ
```json
{json.dumps(evaluation_result, ensure_ascii=False, indent=2)}
```

# æŠ¥å‘Šè¦æ±‚
è¯·ç”Ÿæˆä¸€ä»½ä¸“ä¸šã€è¯¦ç»†çš„Markdownæ ¼å¼è¯„ä¼°æŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹å†…å®¹ï¼š

1. **æŠ¥å‘Šæ ‡é¢˜ä¸æ‘˜è¦**ï¼šç®€è¦æ€»ç»“è¯„ä¼°ç»“æœ
2. **è¯„ä¼°æŒ‡æ ‡ä¸æ–¹æ³•**ï¼šè¯´æ˜ä½¿ç”¨çš„è¯„ä¼°æ ‡å‡†å’Œæ–¹æ³•ï¼Œå¹¶åŒ…å«è¯„ä¼°æ¡†æ¶å›¾
{evaluation_framework_chart}
3. **ç»¼åˆè¯„åˆ†**ï¼šä½¿ç”¨æä¾›çš„è¡¨æ ¼å’Œé¥¼å›¾å±•ç¤ºå„ç»´åº¦è¯„åˆ†
{radar_chart}
4. **è¯¦ç»†åˆ†æ**ï¼š
   - åŠŸèƒ½è¦†ç›–åº¦åˆ†æ
   - ç¼ºé™·å‘ç°èƒ½åŠ›åˆ†æ
   - å·¥ç¨‹æ•ˆç‡åˆ†æ
   - è¯­ä¹‰è´¨é‡åˆ†æ
   - å®‰å…¨ä¸ç»æµæ€§åˆ†æ
5. **é‡å¤æµ‹è¯•ç”¨ä¾‹åˆ†æ**ï¼š
   - é‡å¤æµ‹è¯•ç”¨ä¾‹æ¯”ç‡ä¸ç±»å‹çš„ç»¼åˆåˆ†æ
   - æµ‹è¯•ç”¨ä¾‹åˆå¹¶å»ºè®®
{duplicate_combined_chart}
6. **æµ‹è¯•è¦†ç›–ç‡åˆ†æ**ï¼š
   - å…³é”®æµç¨‹å’ŒåŠŸèƒ½è¦†ç›–æƒ…å†µ
{coverage_chart}
7. **ä¼˜ç¼ºç‚¹å¯¹æ¯”**ï¼šåˆ—å‡ºAIç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ç›¸å¯¹äºäººå·¥æ ‡å‡†çš„ä¼˜åŠ¿å’ŒåŠ£åŠ¿
8. **æ”¹è¿›å»ºè®®**ï¼šç»™å‡º3-5æ¡å…·ä½“å¯è¡Œçš„æ”¹è¿›AIç”Ÿæˆæµ‹è¯•ç”¨ä¾‹çš„å»ºè®®ï¼ŒåŒ…æ‹¬å¦‚ä½•å‡å°‘é‡å¤
9. **ç»¼åˆç»“è®º**ï¼šæ€»ç»“AIæµ‹è¯•ç”¨ä¾‹çš„æ•´ä½“è¡¨ç°å’Œé€‚ç”¨åœºæ™¯

# ç¾åŒ–è¦æ±‚
1. è¯·ä½¿ç”¨æ›´ä¸°å¯Œçš„Markdownæ ¼å¼å…ƒç´ æ¥å¢å¼ºæŠ¥å‘Šçš„å¯è¯»æ€§ï¼Œå¦‚é€‚å½“ä½¿ç”¨åˆ†éš”çº¿ã€å¼•ç”¨å—ã€è¡¨æƒ…ç¬¦å·ç­‰
2. ä¸ºå…³é”®æ•°æ®æ·»åŠ é†’ç›®çš„æ ‡è®°ï¼Œå¦‚é‡è¦çš„è¯„åˆ†ã€æ˜¾è‘—çš„å·®å¼‚ç­‰
3. åœ¨è¯„åˆ†éƒ¨åˆ†ä½¿ç”¨ä¸­æ–‡ç»´åº¦åç§°å’Œæ˜Ÿå·è¯„åˆ†å¯è§†åŒ–
4. ä¸ºæŠ¥å‘Šæ·»åŠ ç®€æ´ç¾è§‚çš„é¡µçœ‰é¡µè„š
5. æ·»åŠ æœ‰é’ˆå¯¹æ€§çš„æ”¹è¿›å»ºè®®ï¼Œä½¿ç»“è®ºæ›´å…·æ“ä½œæ€§

# é¡µè„šæ ¼å¼
è¯·åœ¨æŠ¥å‘Šæœ«å°¾æ·»åŠ ä¸€è¡Œé¡µè„šï¼Œä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š
**ç”Ÿæˆæ—¶é—´ï¼š{{å½“å‰å¹´æœˆæ—¥æ—¶é—´}} â€¢ gogogoå‡ºå‘å–½è¯„ä¼°ä¸­å¿ƒ**

è¯·ç¡®ä¿ä½¿ç”¨ä¸Šé¢æä¾›çš„å›¾è¡¨æ¨¡æ¿ï¼Œè¿™äº›æ¨¡æ¿å·²ç»åŒ…å«äº†ä»è¯„ä¼°ç»“æœä¸­æå–çš„å®é™…æ•°æ®ã€‚
è¿™äº›å›¾è¡¨ä½¿ç”¨çš„æ˜¯è¾ƒä¸ºé€šç”¨çš„Mermaidè¯­æ³•ï¼Œç¡®ä¿ä¸å¤§å¤šæ•°MarkdownæŸ¥çœ‹å™¨å…¼å®¹ã€‚
ä½ å¯ä»¥æ ¹æ®è¯„ä¼°ç»“æœè°ƒæ•´å›¾è¡¨å†…å®¹ï¼Œä½†è¦ä¿æŒ```mermaidè¯­æ³•æ ¼å¼ã€‚
ç›´æ¥ä»¥# å¼€å¤´çš„æ ‡é¢˜å¼€å§‹ä½ çš„æŠ¥å‘Šï¼Œä¸è¦åœ¨å¼€å¤´å†™"markdown"ï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šã€‚
"""

    system_prompt = "ä½ æ˜¯ä¸€ä½ç²¾é€šè½¯ä»¶æµ‹è¯•å’ŒæŠ€æœ¯æ–‡æ¡£å†™ä½œçš„ä¸“å®¶ã€‚è¯·æ ¹æ®è¯„ä¼°ç»“æœç”Ÿæˆä¸€ä»½ä¸“ä¸šã€æ¸…æ™°çš„Markdownæ ¼å¼æŠ¥å‘Šï¼Œå¹¶ä½¿ç”¨Mermaidå›¾è¡¨å¯è§†åŒ–å…³é”®æ•°æ®ã€‚è¯·ç›´æ¥ä¿ç•™å¹¶ä½¿ç”¨æˆ‘æä¾›çš„è¯„åˆ†è¡¨æ ¼æ ¼å¼ï¼Œä¸è¦ä¿®æ”¹å…¶ç»“æ„ã€‚è¯·ç›´æ¥è¾“å‡ºMarkdownæ ¼å¼ï¼Œä¸è¦å°è¯•è¾“å‡ºJSONã€‚ä¸¥æ ¼ç¦æ­¢åœ¨æ–‡æ¡£å¼€å¤´æ·»åŠ 'markdown'è¿™ä¸ªè¯ï¼Œç›´æ¥ä»¥'# 'å¼€å¤´çš„æ ‡é¢˜å¼€å§‹ã€‚ä¸è¦åœ¨å†…å®¹å¤–åŒ…å«```æˆ–```markdownæ ‡è®°ï¼Œå®Œå…¨é¿å…ä½¿ç”¨ä»£ç å—ï¼Œä½†ä¿ç•™æä¾›çš„Mermaidå›¾è¡¨è¯­æ³•ã€‚"

    # ä½¿ç”¨è¾ƒé«˜çš„temperatureå€¼ï¼Œç”Ÿæˆæ›´æœ‰åˆ›æ„çš„æŠ¥å‘Š
    result = await async_call_llm(
        session,
        prompt,
        system_prompt,
        temperature=LLM_TEMPERATURE_REPORT  # ä½¿ç”¨é…ç½®ä¸­çš„è¾ƒé«˜temperatureå€¼
    )

    if not result:
        log_error("ç”ŸæˆMarkdownæŠ¥å‘Šå¤±è´¥", important=True)
        return "# è¯„æµ‹æŠ¥å‘Šç”Ÿæˆå¤±è´¥\n\næ— æ³•ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šï¼Œè¯·æ£€æŸ¥è¯„æµ‹ç»“æœæˆ–é‡è¯•ã€‚"

    # æ£€æŸ¥è¿”å›çš„ç»“æœç±»å‹
    if isinstance(result, dict):
        # å¦‚æœè¿”å›çš„æ˜¯å­—å…¸ï¼Œæ£€æŸ¥æ˜¯å¦åŒ…å«æ–‡æœ¬å†…å®¹
        if "text" in result:
            # è¿”å›æ–‡æœ¬å†…å®¹
            markdown_content = result["text"]
            log("æˆåŠŸç”ŸæˆMarkdownæŠ¥å‘Š", important=True)
            # æ·»åŠ å°å»¶è¿Ÿï¼Œç¡®ä¿æ—¥å¿—é¡ºåº
            await asyncio.sleep(0.1)
            return markdown_content
        elif "error" in result:
            # è¿”å›é”™è¯¯ä¿¡æ¯
            log_error(f"ç”ŸæˆMarkdownæŠ¥å‘Šå¤±è´¥: {result['error']}")
            return f"# è¯„æµ‹æŠ¥å‘Šç”Ÿæˆå¤±è´¥\n\n{result['error']}"
        else:
            # å°è¯•å°†å­—å…¸è½¬æ¢ä¸ºMarkdown
            try:
                md_content = "# AIæµ‹è¯•ç”¨ä¾‹è¯„ä¼°æŠ¥å‘Š\n\n"

                if "evaluation_summary" in result:
                    summary = result["evaluation_summary"]
                    md_content += f"## æ‘˜è¦\n\n"
                    md_content += f"**æ€»ä½“è¯„åˆ†**: {summary.get('overall_score', 'N/A')}\n\n"
                    md_content += f"**æ”¹è¿›å»ºè®®**: {summary.get('final_suggestion', 'N/A')}\n\n"

                if "detailed_report" in result:
                    md_content += f"## è¯¦ç»†è¯„ä¼°\n\n"
                    detailed = result["detailed_report"]

                    for key, value in detailed.items():
                        if isinstance(value, dict) and "score" in value:
                            md_content += f"### {key.replace('_', ' ').title()}\n\n"
                            md_content += f"**è¯„åˆ†**: {value.get('score', 'N/A')}\n\n"
                            md_content += f"**ç†ç”±**: {value.get('reason', 'N/A')}\n\n"

                            if key == "duplicate_analysis" and "merge_suggestions" in value:
                                md_content += f"**åˆå¹¶å»ºè®®**: {value.get('merge_suggestions', 'N/A')}\n\n"

                            if "analysis" in value and isinstance(value["analysis"], dict):
                                analysis = value["analysis"]
                                if "covered_features" in analysis:
                                    md_content += "**è¦†ç›–çš„åŠŸèƒ½**:\n\n"
                                    for feature in analysis["covered_features"]:
                                        md_content += f"- {feature}\n"
                                    md_content += "\n"

                                if "missed_features_or_scenarios" in analysis:
                                    md_content += "**æœªè¦†ç›–çš„åŠŸèƒ½æˆ–åœºæ™¯**:\n\n"
                                    for feature in analysis["missed_features_or_scenarios"]:
                                        md_content += f"- {feature}\n"
                                    md_content += "\n"

                                if "scenario_types_found" in analysis:
                                    md_content += "**å‘ç°çš„åœºæ™¯ç±»å‹**:\n\n"
                                    for scenario in analysis["scenario_types_found"]:
                                        md_content += f"- {scenario}\n"
                                    md_content += "\n"

                log("æˆåŠŸä»å­—å…¸ç”ŸæˆMarkdownæŠ¥å‘Š", important=True)
                # æ·»åŠ å°å»¶è¿Ÿï¼Œç¡®ä¿æ—¥å¿—é¡ºåº
                await asyncio.sleep(0.1)
                return md_content
            except Exception as e:
                log_error(f"ä»å­—å…¸ç”ŸæˆMarkdownæŠ¥å‘Šå¤±è´¥: {e}")
                # å¦‚æœæ— æ³•è½¬æ¢ä¸ºMarkdownï¼Œç›´æ¥è¿”å›JSONå­—ç¬¦ä¸²
                return f"# è¯„æµ‹æŠ¥å‘Š\n\n```\n{json.dumps(result, ensure_ascii=False, indent=2)}\n```"

    # å¦‚æœè¿”å›çš„ä¸æ˜¯å­—å…¸ï¼Œè€Œæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
    if isinstance(result, str):
        log("LLMç›´æ¥è¿”å›äº†Markdownæ–‡æœ¬", important=True)
        # æ·»åŠ å°å»¶è¿Ÿï¼Œç¡®ä¿æ—¥å¿—é¡ºåº
        await asyncio.sleep(0.1)
        # åˆ é™¤Markdownæ–‡æœ¬é¡¶éƒ¨çš„"markdown"å‰ç¼€
        if result.strip().startswith("markdown"):
            result = result.strip().replace("markdown", "", 1).strip()
            log("å·²åˆ é™¤Markdownæ–‡æœ¬é¡¶éƒ¨çš„'markdown'å‰ç¼€", important=True)
            # æ·»åŠ å°å»¶è¿Ÿï¼Œç¡®ä¿æ—¥å¿—é¡ºåº
            await asyncio.sleep(0.1)
        return result

    # å…¶ä»–æƒ…å†µï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
    log_error("æ— æ³•å¤„ç†LLMè¿”å›çš„ç»“æœç±»å‹", {"result_type": type(result).__name__})
    return "# è¯„æµ‹æŠ¥å‘Šç”Ÿæˆå¤±è´¥\n\næ— æ³•è§£æè¯„æµ‹ç»“æœï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼ã€‚" 